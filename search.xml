<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[一次事故]]></title>
    <url>%2F2018%2F04%2F%E4%B8%80%E6%AC%A1%E4%BA%8B%E6%95%85%2F</url>
    <content type="text"><![CDATA[这周五凌晨进行线上数据库的切换，之前已经改成了读新库，这次是把写也切换到新库，是持续一个月工作的最后一次重要变更。 切换的操作步骤已经 review 通过并写在文档中，但实际情况远没有预料的顺利。 之前给的切换时间是 20 秒，也就是最多会有 20 秒写入失败，但实际用了两分半。然后发现新库向某映射表的同步延迟有 15 秒，这个时间是不能接受的，但回滚操作还会导致写库失败并且我们线上验证主要业务流程并没发现问题。过了一会想到前两天遇到过类似问题，是因为机器时间不一致，监控显示延迟而实际正常。查看两台机器时间，确实差了 15 秒。 在调研延迟问题的同时，发现有业务报错，另外的一张表插入失败，唯一索引冲突，经过相关同学调查，原因是部分业务除了写这次切换的表还会写其他表，而切换过程中写入两个表一个成功一个失败就导致了这种异常情况。从日志中取出插入失败的 SQL，手动修补数据后恢复正常。 继续观察业务，日志正常，测试主要业务流程也没问题。1 点半，打车回家。 4 点半还是没有睡着。 7 点醒了，第一件事情是看手机，发现有报警，还好是刚开始报警。看错误日志，认定是数据库中间件有问题，只好先修改业务方代码并紧急上线不使用中间件有问题的功能，从报警到上完线用了三十多分钟，上线后报警立即消失了。 给同事打了几个电话，继续躺回床上，没睡着。去公司后进行一些善后工作，开总结会。 吃一堑长一智吧： 要一直保持警惕，尤其是这种持续时间长的任务，要知道线上的变更会有哪些影响，要找更熟悉业务的同事去聊 虽然在测试环境也演练了切换操作，但要故意拉长切换时间，去发现切换中会有什么问题出现 只背自己的锅 最后再记录下以前遇到的一个问题。在一次重构时发现一个很简单很小的别人写的 BUG，我顺手修改后没有测试此 BUG，上线后过了几天发现出了问题。此 BUG 存在时没有问题是因为有另外一个 BUG，两个 BUG 一起反而接口是正常的。]]></content>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grpc-go client 打印请求的耗时]]></title>
    <url>%2F2018%2F02%2Fgrpc-go%20client%20%E6%89%93%E5%8D%B0%E8%AF%B7%E6%B1%82%E7%9A%84%E8%80%97%E6%97%B6%2F</url>
    <content type="text"><![CDATA[我们在调用 http server 或执行 SQL/redis 命令时会打印出这些外部系统调用的耗时，以快速定位问题。随着对 grpc 使用的增多，为 grpc client 增加此功能也是很有必要的，本文章就简单介绍下处理方法。 这里以官方的例子进行说明 在 grpc.Dial() 中添加中间件 logReqTime 1234567func main() &#123; // Set up a connection to the server. // 添加 grpc.WithUnaryInterceptor(logReqTime()) conn, err := grpc.Dial(address, grpc.WithInsecure(), grpc.WithUnaryInterceptor(logReqTime())) // conn, err := grpc.Dial(address, grpc.WithInsecure()) // ......&#125; logReqTime() 实现如下 123456789func logReqTime() grpc.UnaryClientInterceptor &#123; return func(ctx context.Context, method string, req, reply interface&#123;&#125;, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption) error &#123; start := time.Now() // 取得调用前的时间 err := invoker(ctx, method, req, reply, cc, opts...) // 调用 rpc 函数 cost := time.Since(start) // 取得调用函数的耗时 fmt.Printf(&quot;method[%s] cost[%v]\n&quot;, method, cost) // 打印耗时 return err &#125;&#125; 进行上述两步的修改后，每次发送请求都会执行中间件 logReqTime，即可打印出调用耗时 如果需要打印出调用的 rpc server 地址，可使用 grpc.Peer() 12345678910111213141516func logReqTime() grpc.UnaryClientInterceptor &#123; return func(ctx context.Context, method string, req, reply interface&#123;&#125;, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption) error &#123; start := time.Now() // 使用 grpc.Peer() 取得调用 rpc 服务的地址 p := peer.Peer&#123;&#125; if opts == nil &#123; opts = []grpc.CallOption&#123;grpc.Peer(&amp;p)&#125; &#125; else &#123; opts = append(opts, grpc.Peer(&amp;p)) &#125; err := invoker(ctx, method, req, reply, cc, opts...) cost := time.Since(start) fmt.Printf(&quot;method[%s] call[%s] cost[%v]\n&quot;, method, p.Addr, cost) return err &#125;&#125; 执行结果： 1method[/helloworld.Greeter/SayHello] call[[::1]:50051] cost[3.072303ms]]]></content>
      <tags>
        <tag>go</tag>
        <tag>grpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[json.Marshal 忽略 omitempty 的方法]]></title>
    <url>%2F2018%2F02%2Fjson.Marshal%20%E5%BF%BD%E7%95%A5%20omitempty%20%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[grpc-go 时生成的 pb.go 文件中结构的字段都有 json:&quot;,omitempy&quot; 的 tag，例如： 123type HelloReply struct &#123; Message string `protobuf:&quot;bytes,1,opt,name=message&quot; json:&quot;message,omitempty&quot;`&#125; 在某些情况可能需要将此结构转成 json 输出，并且需要当是零值时不要在 json 串中忽略此字段。 以上面结构为例，默认编码成的 json 串是 {}，但需要的是 {&quot;message&quot;:&quot;&quot;}。 开始想到的方法是用 shell 脚本删除 omitempty，但此方法有可能多删除东西，并且不易管理。最后使用的方法是复制了 encoding/json 库的源码到新的库 my_json，修改这一行中的 omitEmpty 为 false。当需要忽略 omitempty 时，使用 my_json 库即可。 12345678fields = append(fields, fillField(field&#123; name: name, tag: tagged, index: index, typ: ft, omitEmpty: opts.Contains(&quot;omitempty&quot;), // 改为 false quoted: quoted,&#125;))]]></content>
      <tags>
        <tag>go</tag>
        <tag>grpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次性能优化]]></title>
    <url>%2F2017%2F10%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前两天在帮女朋友写代码进行一些数学计算，开始量很小，但后来需要对所有的 32 位数字进行计算。之前的代码无法完成这么大的运算量，所以进行了优化，这篇博客记录代码的优化点。 先通过例子解释一个名词：移位等价 二进制数 0001 的移位等价的数有且只有 0010/0100/1000 0000/0001/0011/0101/0111/1111 这些数移位不等价 下面按照我优化的顺序记录，其中的截图是使用 pprof 生成的，用来找出占用 cpu 时间较多的操作。 优化算法 程序中首先要做的是要找出 32 位数中所有移位不等价的数，我开始的方法是这样的： 使用数组保存所有移位不等价的数 使用两个嵌套的循环分别遍历所有 32 位数和所有已经加入到数组中的数，找出所有移位不等价的数 这个方法的时间复杂度是O(n^2)。而 32 位数一共有 42 亿个，这么大的量级使用 O(n^2）的算法是自寻死路。 优化方法很简单：将数组换成 map，如果一个数的所有移位等价的数都不在 map 中，那么将这个数放入 map。这样时间复杂度就从 O(n^2) 降到 O(n)。 我又做了进一步优化，先算出数 a 最小的移位等价的值 min，再判断一次 min 是否在 map中（减少读 map 的次数）。 移除不必要的重复计算 第一次 pprof 显示耗时最多的是 math.Pow()，查看代码发现数值的移位函数中会使用 math.Pow() 计算 2^n（n 的范围是 [0, 32]），并且移位函数调用的次数非常多。这种情况没必要每次都计算一遍 2^n，修改成当程序启动时计算出需要的平方值然后保存到 map 中，需要时直接从 map 取结果即可。 以数组替换 map pprof 显示访问 map 耗时较长，是因为上面把 2^n 结果保存在了 map 中，因为此 map 的 key 是 [0, 32]，所以可以用数组替换 map，以 [0, 32] 做为数组索引来取得对应的平方值。 定义 slice 时指定容量 growslice 表示 slice 进行了扩容，扩容需要在堆中查找足够大的空间并复制原数据。通过排查找到了有问题的代码，幸运的是这个 slice 的最大长度不会超过32，所以修改为 s := make([]T, 0, 32)。 串行改为并行 整个程序可简单的划为两步：1.找出所有移位不等价的数 2.将这些数进行后续计算。 32 位数一共有 42 亿个数字，要等第一步全部执行完后再执行第二步的话肯定会拉长整个程序的处理时间。 可以将第一步看做生产者，第二步看成消费者，生产者计算出一个有效的数值后将其写入 channel，消费者再从 channel 中取得这些值进行后续计算，这样两步运算能够并行执行，提高效率。 避免加锁 除了使生产者和消费者并行执行外，还可以创建多个生产者和多个消费者，充分利用多核。但生产者在计算移位不等价的数值时需要读写全局的 map，并发情况下肯定需要加锁，对于单个计算耗时很短但量特别大的情况下并行并加锁可能会有反作用。 但是具体到这个 case，因为重量（1 的个数，例如 0101 的重量是 2）不同的数肯定是移位不等价的，这样就可以将一个全局的 map 按重量拆分成多个 map（一个重量用一个 map，32 位的数使用 33 个 map），相同重量的数只在同一个 goroutine 中计算，这样一个 map 只会被一个 goroutine 读写，就没有加锁的必要了。 减少 channel 的读写次数 优化为并行后再次使用 pprof 测试，得到了上图结果。可以看出从 channel 中读数据成了耗时最多的操作。 go 有一句名言: Do not communicate by sharing memory; instead, share memory by communicating. 虽然推荐用 channel 来共享数据，但 channel 并不是对性能没有影响的。我的代码会通过 channel 共享大量数据（10 亿的数量级），而且数据的生产和消费耗时很短，这时对 channel 的操作就成了瓶颈。所以要将操作 channel 的次数降低。 优化方法很简单，之前 channel 的类型是 chan T，将其改为 chan []T，生产者计算出一个值后先保存到 slice ，待 slice 长度达到指定值时再将 slice 写入 channel，相当于将大量小数据打包后再通过 channel 传递。这样明显降低了 channel 的读写次数，优化后读 channel 的 cpu 占用从 54% 降到了 1.6%。 使用高性能机器 公司 32 核测试机比我的 4 核 mac 计算快多了😂 就写到这吧，我要去给女朋友买炸鸡腿了🐔]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go 中的一些坑]]></title>
    <url>%2F2017%2F07%2FGo%20%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91%2F</url>
    <content type="text"><![CDATA[每种语言都有“坑”，有些是语言设计问题，有些是使用者的问题。不管如何，了解这些东西后能让我们的代码更健壮，BUG更少。 资源泄漏 time.Tick() func Tick(d Duration) &lt;-chan Time可用来做定时器，官网上的示例如下： 1234c := time.Tick(1 * time.Minute)for now := range c &#123; fmt.Printf("%v %s\n", now, statusUpdate())&#125; 但使用此函数的话，没有办法释放底层的资源，看下此函数的说明： Tick is a convenience wrapper for NewTicker providing access to the ticking channel only. While Tick is useful for clients that have no need to shut down the Ticker, be aware that without a way to shut it down the underlying Ticker cannot be recovered by the garbage collector; it “leaks”. Unlike NewTicker, Tick will return nil if d &lt;= 0. 下面是验证的例子，会发现 tickLeak() 执行完后 CPU 依然占用很高： 12345678910func tickLeak() &#123; for i := 0; i &lt; 1000; i++ &#123; time.Tick(time.Nanosecond) &#125;&#125;func main() &#123; tickLeak() fmt.Println("tickLeak finished") time.Sleep(15 * time.Second)&#125; 所以应该像上面注释中说的那样，只在不需要关闭 Ticker 时使用 time.Tick()。否则使用 time.NewTicker()，并在不需要时主动调用 func (*Ticker) Stop。 更新 map 中的值 map 中的值是结构体时，想要更新结构体的某一个字段： 123456789101112package maintype T struct &#123; A int B string&#125;func main() &#123; m := make(map[string]T) m["first"] = T&#123;A: 10, B: "ok"&#125; m["first"].A = 1&#125; 这段代码编译会报错： 1.\main.go:10: cannot assign to struct field m[&quot;first&quot;].A in map 要这样写： 1234m[&quot;first&quot;] = T&#123; A: 1, B: m[&quot;first&quot;].B,&#125; 或把 map 的值改成指针类型： 123m := make(map[string]*T)m[&quot;first&quot;] = &amp;T&#123;A: 10, B: &quot;ok&quot;&#125;m[&quot;first&quot;].A = 1 但要注意使用指针时，如果 map 中没有这个 key 的话会 panic: 1panic: runtime error: invalid memory address or nil pointer dereference make slice 时的参数 使用 make 创建 slice 时，可以指定 slice 的容量，减少 append 时重新分配内存的次数。但如果代码是这样写的，那就会引入BUG： 123456789package mainimport "fmt"func main() &#123; s := make([]int, 3) s = append(s, 1, 2, 3) fmt.Println(s)&#125; 上面代码会打印出：[0 0 0 1 2 3]，因为 make 只指定了两个参数，这样 slice 的长度和容量都是 3，即 s 中已经有了三个值为 0 的元素。]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go 中一些操作的性能对比]]></title>
    <url>%2F2017%2F05%2Fgo-compare-op%2F</url>
    <content type="text"><![CDATA[这篇博客对比一些操作的性能情况。 循环遍历 slice 各元素 字符串拼接 循环遍历 slice 各元素 以 RoundRobin 的实例进行说明。在 RoundRobin 中有两种方法返回可用的服务地址 1234type roundrobin struct &#123; i int // 服务地址索引 servers []string // 可用的服务地址&#125; 第一种，每次索引加一后取余数： 123456func (r *roundrobin) module() string &#123; s := r.servers[r.i] r.i++ r.i %= len(r.servers) return s&#125; 第二种，每次索引加一后，判断如果加到最大将索引再置为 0： 12345678func (r *roundrobin) check() string &#123; s := r.servers[r.i] r.i++ if r.i == len(r.servers) &#123; r.i = 0 &#125; return s&#125; 这两种方法结果相同，但性能有一个数量级的差距（查看完整代码）： 12BenchmarkModule-4 100000000 13.9 ns/opBenchmarkCheck-4 2000000000 1.49 ns/op 字符串拼接 测试四种拼接方法，两种字符长度（5个字节和500个字节），两种字符个数(4个字符串和100个字符串）。一共 4×2×2=16个结果。 四种拼接方法如下（查看完整代码） fmt.Sprintf()： 123func byFmt(s []string) string &#123; return fmt.Sprintf("%s%s%s%s", s[0], s[1], s[2], s[3])&#125; 使用加号一次拼接： 123func byPlusOnce(s []string) string &#123; return s[0] + s[1] + s[2] + s[3]&#125; 使用加号多次拼接： 12345678func byPlusSplit(s []string) string &#123; ret := "" ret += s[0] ret += s[1] ret += s[2] ret += s[3] return ret&#125; 使用 buffer： 12345678func byBuffer(s []string) string &#123; buf := bytes.Buffer&#123;&#125; buf.WriteString(s[0]) buf.WriteString(s[1]) buf.WriteString(s[2]) buf.WriteString(s[3]) return buf.String()&#125; 测试结果： 1234567891011121314151617181920$ go test -bench BenchmarkConcat*BenchmarkConcatShortString/fmt-4 2000000 507 ns/opBenchmarkConcatShortString/plusOnce-4 20000000 74.6 ns/opBenchmarkConcatShortString/plusSplit-4 10000000 182 ns/opBenchmarkConcatShortString/buffer-4 10000000 164 ns/opBenchmarkConcatLongString/fmt-4 2000000 912 ns/opBenchmarkConcatLongString/plusOnce-4 3000000 448 ns/opBenchmarkConcatLongString/plusSplit-4 1000000 1058 ns/opBenchmarkConcatLongString/buffer-4 1000000 2046 ns/opBenchmarkConcatManyShortString/fmt-4 200000 8125 ns/opBenchmarkConcatManyShortString/plusOnce-4 2000000 947 ns/opBenchmarkConcatManyShortString/plusSplit-4 200000 11207 ns/opBenchmarkConcatManyShortString/buffer-4 1000000 2214 ns/opBenchmarkConcatManyLongString/fmt-4 100000 15411 ns/opBenchmarkConcatManyLongString/plusOnce-4 200000 7006 ns/opBenchmarkConcatManyLongString/plusSplit-4 3000 438927 ns/opBenchmarkConcatManyLongString/buffer-4 50000 31283 ns/op 根据测试结果速度最快的是byPlusOnce()，而不是网上说的byBuffer()。]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 go 中实现非阻塞的 channel]]></title>
    <url>%2F2017%2F05%2Funblocked_chan%2F</url>
    <content type="text"><![CDATA[今天在写用于限流的漏桶算法，使用了 channel 来模拟“桶”。大致方法是这样： 定时从 channel 中读出数据（模拟桶漏水） 收到请求时如果 channel 没有满，就写入 收到请求时如果 channel 满了，就抛弃请求并返回“超出 QPS 限制”（不要阻塞） 众所周知，channel 是阻塞的，但有办法模拟出第 3 点的要求，代码如下: 123456789101112131415161718192021var bucket = make(chan struct&#123;&#125;)func main() &#123; go leak() for i := 0; i &lt; 10; i++ &#123; time.Sleep(500 * time.Millisecond) select &#123; case bucket &lt;- struct&#123;&#125;&#123;&#125;: fmt.Println(&quot;add data to bucket&quot;) default: // 注意这里 fmt.Println(&quot;bucket is full&quot;) &#125; &#125;&#125;func leak() &#123; tick := time.Tick(time.Second) for range tick &#123; &lt;-bucket &#125;&#125; 运行结果如下（或点击这里修改运行程序） 12345678910bucket is fullbucket is fulladd data to bucketbucket is fulladd data to bucketbucket is fulladd data to bucketbucket is fulladd data to bucketbucket is full 关键在于 select 中的 default，当其他分支阻塞时会执行 default 分支，这样就实现了“非阻塞 channel”的需求。]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－词汇表]]></title>
    <url>%2F2017%2F04%2Fgoogle-api-design-guide%2Fglossary%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Glossary 网络 API（Networked APIs） 通过计算机网络中运行的应用程序接口。它们使用包括 HTTP 在内的网络协议进行通信，并且生产和消费 API 的往往是不同的组织。 Google API Google 服务的网络 API。大部分在 googleapis.com 域名上。不包括客户端库和 SDK 等其他类型的 API。 API 接口（API Interface） 一个 Protocol Buffer 服务的定义。在大多数编程语言中它被映射到一个接口。一个 API 接口可以被多个 API 服务实现。 API 版本（API Version） 一个 API 接口或多个定义在一起的 API 接口的版本。API 版本通常以字符串表示（例如 “v1”）并且以 API 请求和 Protocol Buffer 的包名表示。 API 方法（API Method） API 接口中的一个单独操作。在 Protocol Buffer 中以 rpc 定义，并且在大多数编程语言中映射到 API 接口中的一个函数。 API 请求（API Request） 一个单独的 API 方法调用。它经常用作计费、记录、监控和速率限制的单位。 API 服务（API Service） 一人部署了暴露出网络端点的 API 接口的实现。API 服务以 RFC 1035 DNS 格式的服务名（例如 calendar.googleapis.com）进行标识。 API 端点（API Endpoint） 指向用于 API 服务处理实际 API 请求的网络地址。例如 pubsub.googleapis.com 和 content-pubsub.googleapis.com。 API 产品（API Product） 一个 API 服务加上相关的组件（服务声明、文档、客户端库和服务支持），组合起来以产品的形式提供给用户。例如 Google Calendar API。注意：人们有时会简单地使用 API 表示 API 产品。 API 服务定义（API Service Definition） API 接口的定义（.proto 文件）和 API 服务配置（.yaml 文件）一起定义了API 服务 API 消费者（API Consumer） 消费 API 服务的实体。对于 Google API，API 消费者一般是拥有客户端程序或服务端资源的 Google 项目。 API 生产者（API Producer） 产生 API 服务的实体。对于 Google API，API 生产者一般是拥有 API 服务的 Google 项目。 API 后端（API Backend） 为 API 服务实现了业务逻辑的一组服务和相关的基础设施。 API 前端（API Frontend） 通过 API 服务提供通用功能的一组服务和相关的基础设施，例如负载均衡器和认证服务器。注意：API 前端和后端可能距离很近也可能很远。有时它们可能会编译成一个二进制文件并运行在一个进程中。 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－文件结构]]></title>
    <url>%2F2017%2F04%2Fgoogle-api-design-guide%2Ffile-structure%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - File Structure gRPC API 应该（should） 使用 proto3 在 .proto 文件中定义。 文件中 必须（must） 将高层级和更重要的定义放在其他项目之前。原型文件 应该（should） 参照下面的顺序： 版权和许可协议（如果需要） 按照 syntax, package, option 和 import 的顺序写的原型 API 概述文档 以引入顺序降序排列的 service 定义 资源 message 定义，父资源 必须（must） 在子资源之前定义 RPC 请求和响应的 message 定义，与对应方法的顺序相同。每个请求信息 必须（must） 在对应响应信息之前（如果有的话） 如果一个原型文件包含了所有的 API，那么它应该以 API 名字命名： API Proto Library library.proto Calendar calendar.proto 如果需要的话，可以将一个大 .proto 文件中的服务、资源消息、请求/响应消息移动到单独的文件中。 推荐在单独的文件中保存单独的服务和对应的请求响应消息，将文件命名为 &lt;enclosed service name&gt;.proto。对于只有资源的原型文件，可将它命名为 resources.proto。 proto 文件名 proto 文件 应该（should） 以小写字母下划线分隔的名字命名，并且 一定（must） 要使用 .proto 做为后缀。例如：service_controller.proto。 proto option 为了在不同 API 中生成一致的客户端库，API 开发者 必须（must） 在 .proto 文件中使用一致的 proto option。参照本指南的 API 定义 必须（must） 使用如下的 option： 1234567891011121314151617181920212223242526272829303132syntax = &quot;proto3&quot;;// 包名要以公司名开始，以主版本号结束package google.abc.xyz.v1;// 这个 option 表示 namespace 在 C# 中使用。默认使用包名的帕斯卡命名法，当包名由一个// 单词的当包名由一个单词的字段组成时这样是没问题的。// 例如，包名 &quot;google.shopping.pets.v1&quot; 应该使用 &quot;Google.Shopping.Pets.V1&quot; 格式的// C# namespace。// 但是如果有多个单词组成的字段时，这个 option 就需要避免只有首个单词大写。// 例如，Google Pet Store API 的包名可以是 &quot;google.shopping.petstore.v1&quot;，意味着它// 对应的 C# namespace 是 &quot;Google.Shopping.Petstore.V1&quot;。因为 option 应该将它改为// &quot;Google.Shopping.PetStore.V1&quot;。// 对于 C#/.NET 命名格式的更多信息，请查看[Framework Design Guidelines](https://msdn// .microsoft.com/en-us/library/ms229043)option csharp_namespace = &quot;Google.Abc.Xyz.V1&quot;;// 这个 option 允许 proto 编译器在包名而不是外部类中生成 Java 代码。通过减少一层名字和// 保持与其他大部分不支持外部类相同提高了开发者的使用体验。option java_multiple_files = true;// Java 外部类应该以文件名的首字母大写的驼峰命名法命名。这个类只用于保存 proto 的描述符，// 所以开发者不需要直接使用它。option java_outer_classname = &quot;XyzProto&quot;;// Java 包名必须是添加了合适前缀的 proto 包名option java_package = &quot;com.google.abc.xyz.v1&quot;;// 从包中生成 Objective-C 符号的前缀。最短 3 个字符、全大写并且惯例是使用包名的缩写。// 一些较短但足够唯一不会与其他冲突的名字之后可能会被使用。&apos;GPB&apos; 被 protocol buffer// 保留使用。option objc_class_prefix = &quot;GABCX&quot;; 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－目录结构]]></title>
    <url>%2F2017%2F04%2Fgoogle-api-design-guide%2Fdirectory-structure%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Directory Structure 通常使用 .proto 文件定义 API，使用 .yaml 文件做为配置。 每个 API 服务 必须（must） 有一个 API 目录来存放定义文件和构建脚本。 API 目录 应该（should） 遵循如下的标准结构： API 目录 配置文件 {service}.yaml：主服务的配置文件，google.api.Service 的 YAML 格式 prod.yaml：产品环境配置文件 staging.yaml：Staging 环境配置文件 test.yaml：测试环境配置文件 local.yaml：本地环境配置文件 接口定义 v[0-9]*/*：每一个子目录包含 API 的一个主版本，主要存放原型文件和构建脚本 {subapi}/v[0-9]*/*：每一个 {subapi} 目录包含子 API 的接口定义。每个子 API 可以有它独立的主版本号 type/*： 包含类型定义的原型文件，包括这些：在不同 API 间共享的类型、不同 API 版本间共享的类型或 API 与服务实现间共享的类型。一旦发布，type/* 中定义的类型 不应该（should not） 有破坏兼容性的修改。 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－兼容性]]></title>
    <url>%2F2017%2F04%2Fgoogle-api-design-guide%2Fcompatibility%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Compatibility 本章提供了有关版本控制部分中给出的破坏和保持兼容性修改的详细说明。 并不总是绝对清楚什么是不兼容的修改，这篇指南 应该（should） 被当成参考性的，而不是覆盖到所有情况。 下面列出的这些规则只涉及客户端兼容性，默认 API 作者了解部署（包括实现细节的变化）的需求。 一般的目标是服务端升级 minor 或 patch 不能影响客户端的兼容性： 代码兼容：针对 1.0 编写的代码在 1.1 上编译失败 二进制兼容：针对 1.0 编译的代码与 1.1 客户端的库链接/运行失败（具体的细节依赖客户端，不同情况有不同变化） 协议兼容：针对 1.0 构建的程序与 1.1 服务端通信失败 语义兼容：所有组件都能运行但产生意想不到的结果 简而言之：旧的客户端应该与相同 major 版本的新服务端正常工作，并且能够轻松地升级到新的 minor 版本。 由于客户端使用了自动生成和手写的代码，除了理论上的基于协议的考虑，还有一些实际的问题。通过生成新版本的客户端库来测试你的修改，并保证测试通过。 下面的讨论将 proto 信息分为三类： 请求信息（例如 GetBookRequest） 响应信息（例如 ListBooksResponse） 资源信息（例如 Book，包括在其他资源消息中使用的任何消息） 这三类有不同的规则，例如请求信息只会从客户端发送到服务端，响应信息只会从服务端发送到客户端，但资源信息一般会在两者之间互相发送。尤其是可被修改的资源需要根据读取/修改/写入的循环来考虑。 保持向后兼容的修改 向 API 服务中添加 API 接口 从协议的角度看，这种修改总是安全的。唯一需要考虑的是客户端库可能已经通过手写的代码使用了新 API 接口的名字。如果新接口与其它完全正交，这种情况不太可能发生。如果是已存接口的简化版本，则很可能引起冲突。 向 API 接口中添加方法 除非添加了一个与现有客户端库中方法冲突的方法，这种修改没有问题。 一个会破坏兼容性的例子：如果有 GetFoo 方法，C# 代码生成器已经创建了 GetFoo 和 GetFooAsync 方法。因此从客户端角度来看，在 API 接口中添加 GetFooAsync 方法将会破坏兼容性。 向方法添加 HTTP 绑定 假设绑定没有引入任何歧义，使服务端响应以前被拒绝的 URL 是安全的。当将现有操作应用于新的资源名称时，可能（may） 会这样做。 向请求信息添加字段 添加请求字段可以是兼容的，只要不指定该字段的客户端在新版本中与旧版本表现相同。 会导致错误的最明显例子是分页：如果 API 的 v1.0 版本不支持，除非 page_size 默认值是无穷大（这样是不好的）才能在 v1.1 中加入分页。否则 v1.0 的客户端原本希望通过一次请求取得所有结果，但实际只能取到一部分。 向响应信息添加字段 只要不改变其他响应字段的行为，就可以扩展不是资源的响应消息（例如ListBooksResponse），而不会破坏兼容性。即使导致冗余，任何在旧的响应消息中的字段也应该存在于新的响应中并保持它原来的语义。 例如，1.0 中的一个查询请求的响应有 bool 类型的字段 contained_duplicates 来指示因为重复而忽略掉的结果。在 1.1 中，我们在 duplicate_count 字段中提供更详细的信息，尽管从 1.1 版本来看是多余的，但 contained_duplicates 字段 必须（must） 要保留。 向枚举添加值 只在请求信息中使用的枚举类型可以自由扩展来添加新元素。例如，使用资源视图时，新的视图能够添加到新 minor 版本中。客户端从来不需要接收此枚举，所以也不需要关心它。 对于资源消息和响应消息，默认假设客户端应该处理它意识不到的枚举值。但是 API 作者应该意识到编写能够正确处理新枚举值的代码可能是困难的。应该（should） 在文档中记录当遇到未知枚举值时客户端的期望行为。 proto3 允许客户端接收它们不关心的值并且当执行重新序列化消息时会保持值不变，所以这样就不会打破读取/修改/写入循环的兼容性。JSON 格式允许发送数值，其中该值的“名称”是未知的，但是服务端通常不会知道客户端是否真正知道特定值。因此 JSON 客户端可能知道它们已经收到了以前对他们未知的值，但他们只会看到名称或数字而不是两个都有。在读取/修改/写入循环中将相同的值返回给服务端不应该修改这个值，因为服务端应该理解这两种形式。 添加只输出（output-only）的资源字段 可以（may） 添加仅由服务端提供的资源实体中的字段。服务端 可以（may） 验证请求中的值是否有效，但是如果该值被省略则 一定不能（must not） 失败。 破坏向后兼容的修改 删除/重命名服务、接口、字段名、方法或枚举值 从根本上说，如果客户端代码使用了某些字段，那么删除或重命名它将会破坏兼容性，并且 必须（must） 增加 major 版本号。引用旧名称的一些语言（如 C# 和 Java）在编译时会失败， 另一些语言会引起运行时异常或数据丢失。协议格式的兼容性在这里是无关紧要的。 修改 HTTP 绑定 这里的修改实际指删除和添加。例如，你想要支持 PATCH，但已发布的版本支持 PUT，或者已经使用了错误的自定义动词，你 可以（may） 添加新的绑定，但是 一定不要（must not） 移除旧的，因为和删除服务的方法一样会破坏兼容性。 修改字段类型 尽管新类型是协议兼容的，能够改变客户端库自动生成的代码，因此 必须（must） 要升级 major 版本。会导致需要编译的静态类型的语言在编译期就发生错误。 修改资源名的格式 资源 一定不能（must not） 修改名字－这意味着集合名不能被修改。 不像其他大多数破坏兼容性的修改，这会影响 major 版本号：如果客户端期望使用 v2.0 访问在 v1.0 中创建的资源（或反过来），则应该在两个版本中使用相同的资源名称。 对资源名的验证也 不应该（should not） 改变，原因如下： 如果验证变严格，之前成功能请求现在可能会失败 如果比之前文档中记录的验证要宽松，依据之前文档的客户端可能会被破坏。客户端很可能在其他地方保存了资源名，并且对字符集和名字的长度敏感。或者，客户端可能会执行自己的资源名称验证来保持与文档一致。（例如，当开始支持 EC2 资源的长 ID 时，亚马逊向用户发出了许多警告并提供了迁移的时间） 请注意这样的修改只能在 proto 的文档中可见。因此当评审 CL 时审查除注释外的修改是不够的。 修改已有请求的可见性（visible behavior） 客户端总是依赖 API 的行为和语义，即使没有明确支持或记录此行为。因为在大多数情况下修改 API 的行为和语义在客户端看来是破坏性的。如果某行为不是加密隐藏的，你 应该（should） 假设用户已经依赖它了。 因为这个原因加密分页 token 是个好主意，以防止用户创建自己的 token，以及防止当 token 行为发生变化时可能带来的不兼容性。 在 HTTP 定义中修改 URL 格式 除了上面列出的资源名称的变化，这里还要考虑两种类型的修改： 自定义方法名：虽然不是资源名称的一部分，但自定义方法名称是 REST 客户端 POST 请求 URL 的一部分。更改自定义方法名称不应该破坏 gRPC 客户端，但是公共 API 必须假定它们具有 REST 客户端。 资源参数名：从 v1/shelves/{shelf}/books/{book} 到 v1/shelves/{shelf_id}/books/{book_id} 的修改不会影响替代的资源名称，但可能会影响代码生成。 在资源消息中添加读/写字段 客户端会经常执行读取/修改/写入的操作。大多数客户端不支持它们意识不到的字段值，特别是 proto3 不支持。你可以指定任意消息类型（而不是原始类型）中缺失的字段表示更新时不会被修改，但这样使删除这样的字段变的困难。原始类型（包括 string 和 bytes）不能简单地使用这种方法，因为明确地设置 int32 的值为 0 和不对它设置值在 proto3 中并没有区别。 使用字段掩码来进行所有更新操作不会有问题，因为客户端不会隐式覆盖其不知道的字段。然而这是一个不寻常的决定，因为大部分 API 允许全部资源被更新。 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－版本控制]]></title>
    <url>%2F2017%2F04%2Fgoogle-api-design-guide%2Fversioning%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Versioning 这一章是网络 API 的版本控制指南。因为一个 API 服务 可以（may） 提供多个 API 接口，API 版本策略应用在 API 接口上而不是 API 服务。为了方便，下面的 API 表示 API 接口。 网络 API 应该（should） 使用 Semantic Versioning。对于版本号 MAJOR.MINOR.PATCH： 有不兼容的升级时，增加 MAJOR 添加了能向后兼容的新功能时，增加 MINOR 修改了能向后兼容的 BUG 时，增加 PATCH 根据 API 版本的不同，major 版本号使用不同的规则： 对于 version 1(v1)，major 部分 应该（should） 加上 proto 的包名字，例如 google.pubsub.v1。如果包名包含稳定的类型并且接口不会有不兼容的改变，major 部分 可以（may） 忽略版本号，例如：google.protobuf 和 google.longrunning。 对于除 v1 外的所有版本，major 版本号 必须（must） 加上 proto 的包名字。例如 google.pubsub.v2。 对于 pre-GA 的发布（例如 alpha 和 beta），推荐在版本号中添加后缀，后缀 应该（should） 以 pre-release 的版本名（例如 alpha、beta）和可选的 pre-release 版本号组成。 版本进度的例子： Version Proto Package Description v1alpha v1alpha1 v1 alpha 发布 v1beta1 v1beta1 v1 beta 第一次发布 v1beta2 v1beta2 v1 beta 第二次发布 v1test v1test 带有假数据的内部测试版 v1 v1 major 的版本是 v1，可正式使用 v1.1beta1 v1p1beta1 对 v1 版的首次小版本（minor）修改的 beta 发布 v1.1 v1 小版本升级到 v1.1 v2beta1 v2beta1 v2 beta 第一次发布 v2 v2 major 的版本是 v2，可正式使用 minor 和 patch 的版本号 应该（should） 表现在 API 配置和文档中，一定不要（must not） 写在 proto 的包名中。 注意：Google API 平台目前没有原生支持 minor 和 patch。对于每一个 major 版本只有一套文件和客户端的库。API 作者需要通过文档和发布日志手动记录 minor 和 patch。 新的 major 版本号 一定不要（must not） 依赖 相同 API 之前的 major 版本。在了解相关联的依赖性和稳定性风险后，API 可以（may） 依赖其他 API。一个稳定的 API 版本 必须（must） 只依赖其他 API 的最新稳定版本。 在一段时间内，相同 API 的不同版本 必须（must） 在单个客户端中同时工作。这样才能帮助客户端从旧版 API 平滑迁移到新版 API。 只有当没有依赖后旧版本 API 才能被删除。 被多个 API 共享的通用稳定的数据类型（例如日期和时间） 应该（should） 定义在单独的 proto 包中。如果有必要进行不兼容的修改，则 必须（must） 引入新的类型或包含新 major 版本的包。 向后兼容 定义什么是向后兼容的修改是比较困难的。 下面列出了一些，但如果你有任何疑问，点击这里查看详情。 保持向后兼容的修改 向 API 服务中添加 API 接口 向 API 接口中添加方法 向方法添加 HTTP 绑定 向请求信息添加字段 向响应信息添加字段 向枚举添加值 添加只输出（output-only）的资源字段 破坏向后兼容的修改 删除/重命名服务、接口、字段名、方法或枚举值 修改 HTTP 绑定 修改字段类型 修改资源名的格式 修改已有请求的可见性（visible behavior） 在 HTTP 定义中修改 URL 格式 在资源消息中添加读/写字段 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－使用 proto3]]></title>
    <url>%2F2017%2F04%2Fgoogle-api-design-guide%2Fproto3%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Using proto3 这一章讨论在 API 设计中如何使用 Protocol Buffer。为了简化开发体验并提高运行效率，gPRC API 应该（should） 在 API 定义时使用 Protocol Buffers 第 3 版（proto3）。 Protocol Buffer 是一个为了定义数据结构和编程接口的语言独立平台独立的简单的接口定义语言（IDL）。它支持二进制和文本格式，并且能够在不同的平台不同的协议中使用。 proto3 是 Protocol Buffer 的最新版本，与 proto2 比有如下改变： 原始字段（primitive fields）不再支持 hasField。未设置的原始字段有语言相关的默认值。 消息字段仍然可用，可以使用编译器生成的 hasField 方法或与 null 进行比较或与由具体实现定义的哨兵值比较。 不再支持用户自定义的字段默认值 枚举定义 必须（must） 以 0 开始 不再支持 required 字段 不再支持扩展（extensions），请使用 google.protobuf.Any 由于向后兼容性和运行时兼容性的原因，google/protobuf/descriptor.proto 特殊例外 删除了组语法（group） 删除这些特性是为了让 API 的设计更加简洁可靠和提高性能。例如在记录日志前经常需要过滤一些敏感字段，但当字段是 required 时，这种操作是不可能的。 查看 Protocol Buffers 获取更多信息。 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－文档]]></title>
    <url>%2F2017%2F04%2Fgoogle-api-design-guide%2Fdocumentation%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Documentation 这一章是为 API 添加内部文档的指南。大部分 API 有概述、教程和更高级别的参考文档（此指南不讨论）。API 名、资源名和方法名的信息请查看命名约定。 注释格式 在 .proto 文件中使用 // 来添加注释。 1234// Creates a shelf in the library, and returns the new Shelf.rpc CreateShelf(CreateShelfRequest) returns (Shelf) &#123; option (google.api.http) = &#123; post: &quot;/v1/shelves&quot; body: &quot;shelf&quot; &#125;;&#125; 在服务配置中添加注释 作为在 .proto 文件中添加注释的替代方法，你可以在 API 的 YAML 服务配置文件中添加注释。如果两个文件中都记录了相同的元素，则该文件中的文档将优先于 .proto 中的文档 1234567documentation: summary: Gets and lists social activities overview: A simple example service that lets you get and list possible social activities rules: - selector: google.social.Social.GetActivity description: Gets a social activity. If the activity does not exist, returns Code.NOT_FOUND.... 当在一个 .proto 文件中有多个服务并且要提供特定于服务的文档时，你就需要上面的方法。可以在 YAML 中添加 overview 详细记录 API 的描述信息。但是，一般推荐将注释添加到 .proto。 与 .proto 注释一样，可以在 YAML 文件的注释中使用 Markdown 来提供其他格式。 API 描述 API 描述是一个描述此 API 能做什么，以动词开始的句子。在 .proto 文件中，API 描述以注释的方法添加到对应的 service 上，例如： 1234// Manages books and shelves in a simple digital library.service LibraryService &#123;...&#125; API 描述的其他示例： Shares updates, photos, videos, and more with your friends around the world. Accesses a cloud-hosted machine learning service that makes it easy to build smart apps that respond to streams of data. 资源描述 顾名思义资源描述用来描述资源代表的什么东西。在 .proto 文件中，资源描述作为注释添加到对应消息上，例如： 1234// A book resource in the Library API.message Book &#123; ...&#125; 资源描述的其他示例： A task on the user’s to-do list. Each task has a unique priority. An event on the user’s calendar. 字段和参数描述 用于描述字段和参数的定义，一些示例： The number of topics in this series. The accuracy of the latitude and longitude coordinates, in meters. Must be non-negative. Flag governing whether attachment URL values are returned for submission resources in this series. The default value for series.insert is true. The container for voting information. Present only when voting information is recorded. Not currently used or deprecated. 字段和参数描述: 必须清楚地描述边界条件（描述哪些值有效哪些值无效。API 用户会尽最大的可能来误用服务，而且不能阅读底层代码来弄清楚） 必须指定默认值和默认行为 当是字符串时，要描述语法、允许的字符和需要的编码格式，例如 1-255 characters in the set [A-a0-9] A valid URL path string starting with / that follows the RFC 2332 conventions. Max length is 500 characters. 如果可以的话，提供示例 当字段 必须、仅输入、仅输出 时，必须在字段描述的开始进行说明。默认情况下所有字段和参数都是可选的。例如： 1234567891011message Table &#123; // Required. The resource name of the table. string name = 1; // Input only. Whether to dry run the table creation. bool dryrun = 2; // Output only. The timestamp when the table was created. Assigned by // the server. Timestamp create_time = 3; // The display name of the table. string display_name = 4;&#125; 方法描述 方法描述用来说明方法的作用和操作的资源。通常以第三人称的现在时动词开始。示例： Lists calendar events for the authenticated user. Updates a calendar event with the data included in the request. Deletes a location record from the authenticated user’s location history. Creates or updates a location record in the authenticated user’s location history using the data included in the request. If a location resource already exists with the same timestamp value, the data provided overwrites the existing data. 注意事项 确保描述简洁完整并且容易被理解。不能仅做重述，例如 series.insert 方法的描述不能简单地写成 “Inserts a series”。命名应该包含丰富的信息，大多数读者会阅读描述，因为他们需要比名字本身更多的信息。如果不知道在描述中要写什么，试着回答下面的问题： 它是什么 成功或失败后会导致什么。什么会导致失败。 是幂等的吗 单位是什么（例如：米、度、像素） 接收参数的范围 副作用是什么 如何使用 常见错误是什么 是否总是存在（例如：“Container for voting information. Present only when voting information is recorded.”） 是否有默认值 惯例 本节列出了文本描述和文档的一些使用惯例。使用 ID 表示标识符（而不使用 Id 或 id）。使用 JSON 表示数据格式（而不使用 Json 或 json）。所有字段/参数使用 code font 的格式，字符串要用引号括起来。 ID JSON RPC REST property_name 或 &quot;string_literal&quot; true / false 语言风格 和命名约定一样，在写注释时推荐使用简洁一致的词语和风格，让母语非英语的读者容易理解。因此要避免行话、俚语、复杂的隐喻、流行文化或其他不容易理解的内容。使用友好专业的风格直接与读者“交谈”，并尽可能保持注释的简洁。请记住，大部分读者只想知道如何使用 API，而不是阅读你的文档！ 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－设计模式]]></title>
    <url>%2F2017%2F04%2Fgoogle-api-design-guide%2Fdesign-patterns%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Design Patterns 空响应体 标准的 Delete 方法 必须（must） 返回 google.protobuf.Empty 来实现全局一致性。它还可以防止客户端依赖于在重试期间不可用的附加元数据。因为随着时间推移对于自定义方法， 对于自定义方法，它们 必须（must） 具有自己的 XxxResponse 消息，即使它们是空的，因为功能很可能随着时间的推移而增加，并且需要返回附加数据。 范围字段 表示范围的字段 应该（should） 使用符合命名约定的半开半闭区间 [start_xxx, end_xxx)，例如 [start_key, end_key) 或 [start_time, end_time)。C++ STL 和 Java 标准库经常使用半开半闭的语义。API 应该（should） 避免使用表示区间的其他方法，例如 (index, count) 或 [first, last]。 资源标签 在面向资源的 API 中，资源结构由 API 定义。为了允许客户端向资源附加少量且简单的元数据（例如将一台虚拟机资源标记为数据库服务器），API 应该（should） 使用在 google.api.LabelDescriptor 中描述的资源标签设计模式。 API 应该（should） 在资源定义中添加字段 map&lt;string, string&gt; labels： 1234message Book &#123; string name = 1; map&lt;string, string&gt; labels = 2;&#125; 耗时操作 如果一个 API 方法需要花费较长时间运行，可以将其设计成向客户端返回一个表示长时间运行的资源，客户端可通过这个资源来获取操作的执行进度并取得执行结果。Operation 定义了耗时操作的标准接口。不能（must not） 为 API 使用自定义的耗时操作接口以免打破一致性。 资源 必须（must） 作为响应消息直接返回，并且对资源操作的结果 应该（should） 反应在 API 中。例如：当创建资源时这个资源 应该（should） 显示在 LIST 和 GET 方法中，并且 应该（should） 指示出这个资源还没有准备好。如果方法不需要长期执行，当操作完成时 Operation.response 字段应该包含直接返回的消息。 列表分页 即使结果集很小，可 LIST 的集合也 应该（should） 支持分页。 理由：尽管向已有的 API 添加分页功能从 API 的视角来看是纯粹的增加功能，但它实际会改变行为。不知道有分页功能的已有客户端会错误地将取到的第一页数据当成全部数据。 为了在 List 方法中支持分页， API 应该（shall）： 在 List 方法的请求信息中定义一个 string 字段 page_token。客户端通过这个字段来请求指定的某一页。 在 List 方法的请求信息中定义一个 int32 字段 page_size。客户端通过这个字段来指定返回结果的最大数量。服务端可以进一步限制在单个页面中返回的最大结果数量。page_size 是 0 时，将由服务端决定返回结果的数量。 在 List 方法的响应信息中定义一个 string 字段 next_page_token。这个字段表示取得下一页的页码。空字符串表示没有更多数据了。 为了取得下一页的结果，客户端 应该（shall） 将响应中的 next_page_token 传入下次的请求： 123456789101112rpc ListBooks(ListBooksRequest) returns (ListBooksResponse);message ListBooksRequest &#123; string name = 1; int32 page_size = 2; string page_token = 3;&#125;message ListBooksResponse &#123; repeated Book books = 1; string next_page_token = 2;&#125; 当客户端在 query 参数传入除 page token 之外的参数时，如果 query 参数与 page token 不一致，服务 必须（must） 拒绝此请求。 page token 的内容 应该（should） 是对 web 安全的 BASE64 编码后的 protocol buffer，这样就不会有兼容性问题。page token 中存在敏感信息时，应该（should） 将其加密。服务端 必须（must） 通过以下方法来防止通过篡改 page token 来获取敏感信息的问题： 根据后续请求指定 query 参数 在 page token 中仅引用服务端的状态 在 page token 中加密并签名 query 参数，并且在每次调用中对这些参数进行验证和鉴权 分页功能也 可以（may） 在响应中通过名为 total_size 类型为 int32 的字段来提供查询资源的总数量。 列出子集合 API 有时需要客户端对子集合进行 List/Search 操作。例如一个 API 有书架集合，每个书架有书的集合，客户端想要在所有书架中搜索一本书。这种情况下推荐在子集合上使用标准的 List，并且为父集合指定通配符 &quot;-&quot;。例如： 1GET https://library.googleapis.com/v1/shelves/-/books?filter=xxx 注意：使用 &quot;-&quot; 而非 &quot;*&quot; 是为了避免 URL 转义。 从子集合中取得唯一资源 有时子集合中的资源具有在其父集合内唯一的标识符，在这种情况下通过 Get 来取得某资源而不需要知道它的父集合可能是有用的。在这种情况下，建议使用标准 Get，并为资源唯一的所有父集合指定通配符 &quot;-&quot;。例如： 1GET https://library.googleapis.com/v1/shelves/-/books/&#123;id&#125; 响应 必须（must） 使用资源的带有父集合标识符的规范名称。例如上面的请求应该返回名称类似 shelves/shelf713/books/book8141 的资源，而不是 shelves/-/books/book8141。 排序 如果 API 方法允许客户端指定列表结果的排序顺序，请求消息中 应该（should） 包含如下字段： 1string order_by = ...; 这个值 应该（should） 遵循 SQL 语法：用逗号分隔的字段列表。例如：&quot;foo,bar&quot;。默认升序排列。应该（should） 给字段添加后缀 &quot; desc&quot; 来表示降序。例如：&quot;foo desc,bar&quot;。 多余的空格可以忽略，&quot;foo,bar desc&quot; 和 &quot; foo , bar desc &quot;是相等的。 请求校验 如果 API 方法有副作用，并且需要仅验证请求而不产生副作用，请求消息 应该（should） 包含一个字段： 1bool validate_only = ...; 当此字段设置为 true 时，服务端 一定不要（must not） 执行任何有副作用的操作，而是对请求进行校验。 校验成功时 一定（must） 要返回google.rpc.Code.OK，并且使用相同请求信息的完整请求 不应该（should not） 返回 google.rpc.Code.INVALID_ARGUMENT。注意，可能因为其他错误（比如 google.rpc.Code.ALREADY_EXISTS 或竞态条件）此请求还是会失败。 请求重入 对于网络 API，幂等是很重要的，因为当有网络异常时它们能够安全地进行重试。然而一些 API 并不容易实现幂等性，例如需要避免不必要重复的创建资源操作。对于这类情况，请求信息 应该（should） 包含一个唯一 ID（例如 UUID），这样服务端能够通过此 ID 来检测重复，保证请求只被处理一次。 123// 服务端用于检测重复请求的唯一 ID// 此字段应该命名为 `request_id`string request_id = ...; 因为客户端很可能没有接收到之前的响应，所以当检测到重复请求后，服务端 应该（should） 返回之前成功的响应。 枚举默认值 每个枚举定义 必须（must） 以 0 值开始，用于当枚举值没有明确指定时。API 必须（must） 在文档中说明如何处理 0 值。 如果有通用的默认行为，应该（should） 使用枚举值 0。API 应该在文档中说明期待的行为。 如果没有通用的默认行为，枚举值 0 应该（should） 命名为 ENUM_TYPE_UNSPECIFIED 并且和错误 INVALID_ARGUMENT 一起使用。 123456789101112enum Isolation &#123; // 未指定 ISOLATION_UNSPECIFIED = 0; // 快照读。如果所有读写都不能在并发事务中逻辑地序列化，则会发生冲突 SERIALIZABLE = 1; // 快照读。并发事务向同一行写入时导致冲突 SNAPSHOT = 2; ...&#125;// 当未指定时，服务器将使用 SNAPSHOT 或更高的隔离级别Isolation level = 1; 一个惯用名称 可以（may） 用于 0 值，例如，google.rpc.Code.OK 是指定不存在错误的惯用方法。在这种情况下，OK 与枚举类型中的 UNSPECIFIED 在语义上是相等的。 在存在本质上合理和安全的默认情况下，可以（may） 使用 0 值。例如，在资源视图枚举中 BASIC 是 0 值。 语法句法 在某些 API 设计中，有必要为某些数据格式定义简单的语法，例如可接受的文本输入。为了在不同 API 中提供一致的开发体验和减少学习曲线，API 设计者 必须（must） 使用 ISO 14977 扩展的 Backus-Naur 表格（EBNF）句法来定义这些语法。 1234567Production = name &quot;=&quot; [ Expression ] &quot;;&quot; ;Expression = Alternative &#123; &quot;|&quot; Alternative &#125; ;Alternative = Term &#123; Term &#125; ;Term = name | TOKEN | Group | Option | Repetition ;Group = &quot;(&quot; Expression &quot;)&quot; ;Option = &quot;[&quot; Expression &quot;]&quot; ;Repetition = &quot;&#123;&quot; Expression &quot;&#125;&quot; ; 注意：TOKEN 表示在语法之外定义的终端。 整数类型 在API 设计中，不应该（should not） 使用像 uint32 和 fixed32 这种无符号整型，这是因为一些重要的编程语言和系统（例如 Java, JavaScript 和 OpenAPI）不能很好地支持它们并且更容易导致溢出的问题。另一个问题是，不同的 API 很可能对同一个资源使用不匹配的有符号和无符号类型。 在大小和时间这种负数没有意义的类型中 可以（may） 使用且仅使用 -1 来表示特定的意义，例如到在文件结尾（EOF）、无穷的时间、无资源限额或未知的年纪。当这样使用负数时，必须（must） 在文档中明确说明以防止混淆。API 生成器也应该在文档中记录隐式默认值 0 表示的行为。 部分响应 客户端有时只需要响应信息中的特定子集。一些 API 平台提供了对部分响应的原生支持。Google API 平台通过响应字段掩码来提供支持。对于任一 REST API 调用，有一个隐式的系统 query 参数 $fields，它是 google.protobuf.FieldMask 的 JSON 表示。在返回给客户端之前，响应消息会被 $fields 字段过滤。此行为是在 API 平台自动执行的。 1GET https://library.googleapis.com/v1/shelves?$fields=name 资源视图 为了减少网络流量，允许客户端限制服务器在其响应中返回的资源的哪些部分是有用的，返回资源的视图而不是全部资源表示。API 中的资源视图是通过向请求添加参数来实现的，该参数允许客户端在响应中指定要接收资源的哪个视图。 此参数： 应该（should） 是枚举类型 必须（must） 命名为 view 枚举中的每个值定义了资源的哪部分（字段）在响应中会被返回。文档中 应该（should） 明确记录每个 view 值会返回什么。 123456789101112131415161718192021222324package google.example.library.v1;service Library &#123; rpc ListBooks(ListBooksRequest) returns (ListBooksResponse) &#123; option (google.api.http) = &#123; get: &quot;/v1/&#123;name=shelves/*&#125;/books&quot; &#125; &#125;;&#125;enum BookView &#123; // 响应中只包含作者、标题、ISBN 和唯一的图书 ID。这是默认值。 BASIC = 0; // 返回所有信息，包括书中的内容 FULL = 1;&#125;message ListBooksRequest &#123; string name = 1; // 指定返回图书资源的哪些部分 BookView view = 2;&#125; 对应的 URL： 1GET https://library.googleapis.com/v1/shelves/shelf1/books?view=BASIC 可以在 标准方法 一章中查看更多关于方法定义、请求和响应的内容。 ETag ETag 是一个不透明的标识符，允许客户端进行条件请求。为了支持 ETag，API 应该（should） 在资源定义中包含一个字符串字段 etag，它的语义 必须(must) 与 ETag的常用用法相匹配。通常，etag 包含由服务器计算出的资源指纹。更多详细信息，请参阅维基百科和 RFC 7232。 ETags 可以强验证或弱验证，其中弱验证的ETag 以 W / 为前缀。在这种情况下，强验证意味着具有相同 ETag 的两个资源具有相同的内容和相同的额外字段（Content-Type）。这意味着强验证的 ETag 允许缓存稍后组装的部分响应。 相反，具有相同弱验证 ETag 值的资源意味着这些表示在语义上是等效的，但不一定每字节都相同，因此不适合于字节范围请求的响应缓存。 1234// 强验证的 ETag（包含引号）&quot;1a2f3e4d5b6c7c&quot;// 弱验证的 ETag（包含前缀和引号）W/&quot;1a2b3c4d5ef&quot; 输出字段 API 可能希望将由客户端提供的字段和只由服务端在特定资源上返回的字段进行区分。对于仅输出的字段，**必须（shall）**记录字段属性。 请注意，如果客户端在请求中设置了仅输出（output only）字段，或者客户端使用仅输出字段指定了一个 google.protobuf.FieldMask，则服务器 必须（must） 接受该请求而不能出错。这意味着服务器 必须（must） 忽略仅输出字段的存在及其任何指示。这个建议的原因是因为客户端通常会将服务器返回的资源重用为另一个请求的输入，例如一个获取到的 Book 将在 UPDATE 方法中被再次使用。如果要验证仅输出字段，客户端需要做清除输出字段的额外工作。 12345message Book &#123; string name = 1; // 只用做输出 Timestamp create_time = 2;&#125; 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang struct 转 json 时如何忽略部分字段]]></title>
    <url>%2F2017%2F04%2Fgolang%20struct%20%E8%BD%AC%20json%20%E6%97%B6%E5%A6%82%E4%BD%95%E5%BF%BD%E7%95%A5%E9%83%A8%E5%88%86%E5%AD%97%E6%AE%B5%2F</url>
    <content type="text"><![CDATA[将字段首字母改为小写或添加 json:&quot;-&quot; 标签能够在 json.Marshal() 时忽略指定字段，但此文章想讨论的是在不修改原 struct 结构的前提下过忽略部分字段的方法。 为什么会有这种需求呢？如果要转为 json 的 struct 定义在依赖包中或有其他地方需要输出这些字段，这时就不能修改原 struct。 定义只有必要字段的新 struct 定义新 struct，在新 struct 中只保留必要字段。 123456789101112131415type source struct &#123; A int `json:"a"` B int `json:"b"`&#125;type target struct &#123; A int `json:"a"`&#125;func main() &#123; s := source&#123;A: 1, B: 2&#125; t := target&#123;A: s.A&#125; bytes, _ := json.Marshal(t) fmt.Println(string(bytes))&#125; 这是最容易想到的方法，但当字段较多或 struct 较复杂（比如嵌套多层其他 struct）时就会有很多将 source 的字段赋值给 target 的操作。 定义 tag 不同结构相同的 struct 此方法仅适用 golang 1.8+，1.8 之后结构相同但 tag 不同的 struct 之间能够强制转换。利用这个特性，我们能简化掉字段赋值的操作。完整示例点击这里。 12345678910111213141516type source struct &#123; A int `json:"a"` B int `json:"b"` // 注意这里&#125;type target struct &#123; A int `json:"a"` B int `json:"-"` // 注意这里&#125;func main() &#123; s := source&#123;A: 1, B: 2&#125; t := target(s) bytes, _ := json.Marshal(t) fmt.Println(string(bytes))&#125; 通过 map 转换 json 和 struct 转换时，struct 必须提前定义好。如果不知道结构或不想定义 struct，可以将其转为 interface{} 123456func main() &#123; bytes := []byte(`&#123;"test":"abc"&#125;`) var f interface&#123;&#125; json.Unmarshal(bytes, &amp;f) fmt.Println(f)&#125; 上面的执行结果是 map[test:abc]。 所以可以将原 struct 转为 map[string]interface{}，将需要的字段保存入新的 map[string]interface{}，然后转为 json： 12345678910111213141516171819202122232425262728293031type obj map[string]interface&#123;&#125;func trim(source obj, target obj) obj &#123; out := make(obj) for k, v := range source &#123; if vv, find := target[k]; find &#123; switch vv.(type) &#123; case obj: out[k] = make(obj) if len(vv.(obj)) == 0 &#123; out[k] = v &#125; else &#123; out[k] = trim(v.(map[string]interface&#123;&#125;), vv.(obj)) &#125; case []obj: if len(vv.([]obj)) == 0 &#123; out[k] = v &#125; else &#123; out[k] = make([]obj, 0) for i := range v.([]interface&#123;&#125;) &#123; o := trim(v.([]interface&#123;&#125;)[i].(map[string]interface&#123;&#125;), vv.([]obj)[0]) out[k] = append(out[k].([]obj), o) &#125; &#125; default: out[k] = v &#125; &#125; &#125; return out&#125; trim() 的 source 参数是原始 struct，target 参数中只保留需要的字段。原始 struct 和 target 示例： 1234567891011121314151617181920212223242526272829type T1 struct &#123; Field1 string `json:"field_1"` Field2 []int `json:"field_2"` Field3 int `json:"field_3"`&#125;type T2 struct &#123; Field1 string `json:"field_1"` Field2 []int `json:"field_2"` Field3 int `json:"field_3"` T1 T1 `json:"t_1"`&#125;// 原始 structtype ComplexStruct struct &#123; T1 Array []T1 `json:"array"` T2 T2 `json:"t_2"`&#125;// target 中记录需要的 key，值为对象时使用 obj&#123;&#125;，值为对象数组时用 []obj&#123;&#125;，其他类型用""即可target := obj&#123; "array": []obj&#123; &#123; "field_1": "", "field_3": "", &#125;, &#125;, "t_2": obj&#123; "t_1": obj&#123;&#125;, &#125;,&#125; trim() 的返回值是只保留需要字段的 map[string]interface{}，再将其 json.Marshal()即可 123out := trim(source, target)bytes, _ = json.MarshalIndent(out, "", " ")fmt.Println(string(bytes)) 完整代码请看 gist 或 play （只是 demo，没经过大量测试）。使用这种方法只需要定义出 target，不需要像上两个方法那样重新定义 struct，代码会更简洁一些。]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－命名约定]]></title>
    <url>%2F2017%2F04%2Fgoogle-api-design-guide%2Fnaming-conventions%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Naming Conventions 为了在长期和大量使用的 API 中提供统一的开发体验，API 中的所有名字 应该（should） : 简单 直观 一致 此文章讨论了接口、资源、集合、方法和消息的名字。 因为很多开发者的母语并不是英语，这些命名约定通过鼓励使用简单、统一的短词汇来命名方法和资源来保证大部分开发者能够容易理解 API。 API 中的名字 应该（should） 使用美式英语，例如：license（不是 licence），color（不是 colour）。 使用常用的简短形式或缩写，例如： API 比 Application Programming Interface 更好。 尽量使用直接、熟悉的术语，例如：描述对资源的删除（销毁）时，delete 比 erase 更好。 对相同的概念使用相同的名字或术语，包括在 API 中共享的概念。 避免名字重用，对不同的概念要使用不同名字。 避免使用在 API 上下文中会造成混乱的过于通用的名字，它们会导致对 API 概念的误解。应该选择能够精确描述概念的名字。这对于定义一阶 API 元素的名称尤其重要。因为名字与上下文相关，所以并没有明确的名字黑名单。Instance, info 和 service 是会产生问题的名字。应该选择能够明确表达出 API 概念（例：instance 表示什么的实例？）并且容易与其他相关概念有区分（例：alert 的意思是规则，信号还是通知？）的名字。 谨慎使用会与常用编程语言中的关键字有冲突的名字。 产品名 产品名是指 API 的产品营销名称，例如 Google Calendar API。在 API、UI、文档、服务条款、结账单和商业合同中使用的产品名称 应该（should） 一致。 Google API 必须（must） 使用 Google 作为产品名的前缀，除非它们像 Gmail, Nest, Youtube 这种有不同的品牌。一般来说产品名 应该（should） 由产品和市场部门决定。 下表列出了所有相关 API 名称及其一致性的示例，有关各自名称及其约定的更多详细信息，请继续往下看。 API 名 示例 产品名 Google Calendar API 服务名 calendar.googleapis.com 包名 google.calendar.v3 接口名 google.calendar.v3.CalendarService 资源目录 //google/calendar/v3 API 名 calendar 服务名 服务名 应该（should） 是一个能够被解析为一个或多个网络地址的合法 DNS 名字。公有 Google API 的服务名遵循如下模式：xxx.googleapis.com。例如：谷歌日历的服务名是 calendar.googleapis.com。 如果一个 API 由多个服务组成，它们 应该（should） 以能够提高可发现性的方法命名。一种方法是为这些服务名使用相同的前缀。例如服务 build.googleapis.com 和 buildresults.googleapis.com 都是 Google Build API 的一部分。 包名 在 .proto 文件中定义的包名 应该（should） 与产品名和服务名相同。有版本号的包名 必须（must） 以版本号结尾。例如： 12// Google Calendar APIpackage google.calendar.v3; 不与服务直接关联的抽象 API，例如 Google Watcher API 应该（should） 使用与产品名相同的 proto 包名： 12// Google Watcher APIpackage google.watcher.v1; 在 .proto 文件中指定的 Java 包名 必须（must） 符合标准 Java 包名的前缀（com., edu., net. 等）。例如： 1234package google.calendar.v3;// 指定 Java 包的名字，使用标准前缀 &quot;com.&quot;option java_package = &quot;com.google.calendar.v3&quot;; 集合 ID 集合 ID 应该（should） 使用美式英语的、复数形式的、首字母小写的驼峰命名法，例如：events, children 或 deletedEvents。 接口名 为了避免和形如 pubsub.googleapis.com 的资源名混淆，术语 接口名 指的是在 .proto 文件中定义 service 时使用的名字： 12345// Library is the interface name.service Library &#123; rpc ListBooks(...) returns (...); rpc ...&#125; 你可以认为 服务名 是指一组 API 的具体实现，接口名 是指一个 API 的抽象定义。 接口名称 应该（should） 使用直观的名词，如 Calendar 或 Blob。不应该（should not） 与编程语言中已有的任何概念或运行时库冲突（如：File）。 当 接口名 与 API 中其他名字冲突时，应该为其加上前缀（如 Api 或 Service）来进行区分。 方法名 在其 IDL 规范中，服务 可以（may） 定义与集合和资源上的方法相对应的一个或多个RPC方法。方法名 应该（should） 遵循像 VerbNoun 这样首字母大写的驼峰命名法的命名约定，其中名词（Noun）通常是资源类型。 动词（Verb） 名词（Noun） 方法名 请求信息 响应信息 List Book ListBooks ListBooksRequest ListBooksResponse Get Book GetBook GetBookRequest Book Create Book CreateBook CreateBookRequest Book Update Book UpdateBook UpdateBookRequest Book Rename Book RenameBook RenameBookRequest RenameBookResponse Delete Book DeleteBook DeleteBookRequest google.protobuf.Empty 消息名 RPC 方法的请求与响应消息 应该（should） 以方法名分别加上 Request 和 Response 的方式命名。除非方法的请求或响应类型如下： 空消息（使用 google.protobuf.Empty） 资源类型 代表一种操作的资源 枚举名 枚举类型的名字 必须（must） 使用首字母大写的驼峰命名法。 枚举值 必须（must） 以下划线分隔且字母全部大写的方式来命名（例如：CAPITALIZED_NAMES_WITH_UNDERSCORES）。每个枚举值 必须（must） 以分号而不是逗号结尾。第一个值 应该（should） 命名为 ENUM_TYPE_UNSPECIFIED，用于当没有明确指定枚举值时返回。 123456enum FooBar &#123; // 第一个表示默认值，并且一定等于 0 FOO_BAR_UNSPECIFIED = 0; FIRST_VALUE = 1; SECOND_VALUE = 2;&#125; 字段名 在 .proto 文件中定义的字段名 必须（must） 以下划线分隔且字母全部小写的方式来命名（例如：lower_case_underscore_separated_names）。这些名字会遵守各编程语言的命名约定来映射到生成的代码中。 重复字段名（Repeated field） API 中的重复字段 必须（must） 使用合适的复数形式。这符合现有 Google API 的惯例以及外部开发人员的通常期望。 时间和间隔 应该（should） 使用 google.protobuf.Timestamp并且字段名 应该（should） 以 time 结尾来表示独立于任一时区的时间点。例如 start_time, end_time。 如果表示一个活动的时间，字段名 应该（should） 使用 verb_time 格式，如 create_time, update_time。避免使用动词的过去时形式，如 created_time 或 last_updated_time。 应该（should） 使用 google.protobuf.Duration 来表示一个时间段。 1234message FlightRecord &#123; google.protobuf.Timestamp takeoff_time = 1; google.protobuf.Duration flight_duration = 2;&#125; 如果因为遗留系统或兼容原因要使用整形来表示时间相关的字段（包含墙上时间、时间段、延迟），字段名 必须（must） 有如下形式： 1xxx_&#123;time|duration|delay|latency&#125;_&#123;seconds|millis|micros|nanos&#125; 1234message Email &#123; int64 send_time_millis = 1; int64 receive_time_millis = 2;&#125; 如果因为遗留系统或兼容原因要使用字符串来表示时间戳，字段名 不应该（should not） 包含任何单位后缀。应该（should） 使用形如 2014-07-30T10:43:17Z 的 RFC 3339 格式。 日期与时间 应该（should） 使用 google.type.Date 并且字段名以 _date 结尾来表示独立于时区与时间的日期。如果必须以字符串表示，应该使用形如 YYYY-MM-DD 的 ISO 8601 日期格式（例如 2014-07-30）。 应该（should） 使用 google.type.TimeOfDay 并且字段名以 _time 结尾来表示独立于时区与日期的时间。如果必须以字符串表示，应该使用形如 HH:MM:SS[.FFF] 的 ISO 8601 的 24 小时时间格式（例如 14:55:01.672）。 1234message StoreOpening &#123; google.type.Date opening_date = 1; google.type.TimeOfDay opening_time = 2;&#125; 数量 以整形表示的数量 必须（must） 包含单位。 1xxx_&#123;bytes|width_pixels|meters&#125; 如果表示物品的数量，字段名 应该（should） 使用 _count 做为后缀，如 node_count。 List 过滤字段 如果 List 方法支持过滤资源，包含过滤表达式的字段 应该（should） 命名为 filter。例： 1234567message ListBooksRequest &#123; // 父资源名 string parent = 1; // 过滤表达式 string filter = 2;&#125; List 响应 List 方法的响应消息中包含资源列表的字段名字 必须（must） 是资源名的复数形式。例如，方法 CalendarApi.ListEvents() 必须（must） 定义响应消息 ListEventsResponse，此消息中包含名为 events 的重复字段来用于返回资源列表。 123456789101112131415161718service CalendarApi &#123; rpc ListEvents(ListEventsRequest) returns (ListEventsResponse) &#123; option (google.api.http) = &#123; get: &quot;/v3/&#123;parent=calendars/*&#125;/events&quot;; &#125;; &#125;&#125;message ListEventsRequest &#123; string parent = 1; int32 page_size = 2; string page_token = 3;&#125;message ListEventsResponse &#123; repeated Event events = 1; string next_page_token = 2;&#125; 驼峰命名法 除了字段名和枚举值，在 .proto 文件中的所有定义 必须（must） 使用首字母大写的驼峰命名法。 名字缩写 对于像 config 和 spec 这种被软件工程师熟知的缩写，在 API 定义中 应该（should） 使用缩写而不是其完整形式，这会使代码便于读写。在正式的文档中 应该（should） 使用其完整形式。例如： config (configuration) id (identifier) spec (specification) stats (statistics) 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－错误处理]]></title>
    <url>%2F2017%2F04%2Fgoogle-api-design-guide%2Ferrors%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Errors 本章简单介绍 Google API 的错误模型以及开发人员如何正确生成和处理错误的一般指导。 Google API 使用了简单的协议无关的错误模型，这允许我们在不同 API，不同协议（例如 gRPC 或 HTTP），不同的错误上下文（如同步、批量处理、工作流错误）中提供相同的使用体验。 错误模型 错误模型由 google.rpc.Status 定义。如下所示： 123456789101112package google.rpc;message Status &#123; // 容易被客户端处理的简单错误码，实际的错误码定义在`google.rpc.Code` int32 code = 1; // 易于开发者阅读的错误信息，它应该解释错误并且提供可行的解决方法 string message = 2; // 附加的错误信息，客户端能够通过它处理错误，例如重试的等待时间或者帮助页面链接 repeated google.protobuf.Any details = 3;&#125; 因为大部分 Google API 使用面向资源的设计，所以错误处理通过在大量资源上使用一小组标准错误也遵循了相同的设计原则。例如，服务端使用一个标准的 google.rpc.Code.NOT_FOUND 错误码加上特定的资源名来表示“未找到”错误，而不是定义不同种类的“未找到”错误。更少的错误状态减少了文档的复杂性，在客户端的库中提供更好的习惯性映射，在不限制可包含信息的情况下减少了客户端逻辑的复杂性。 错误码 Google API 必须（must） 使用 google.rpc.Code 中定义的标准错误码。单独的 API 应该（should） 避免定义附加错误码，因为开发者非常不喜欢为大量错误码编写处理逻辑。作为参考，每个 API 处理平均 3 个错误码意味着大部分程序逻辑在进行错误处理，这并不是好的开发体验。 错误消息 错误消息应该帮助用户轻松并快速地 理解并解决 API 错误。通常情况请参考如下规则： 不要假设用户非常了解你的 API。用户可能是客户端开发者、运维人员、IT 人员或者 app 的普通用户。 不要假设用户了解服务实现的细节或熟悉错误上下文（例如日志分析）。 如果可能的话，应构建错误消息，以便技术用户（但不一定是 API 的开发人员）可以对错误进行响应并更正。 保持错误信息的简短。如果需要的话，提供链接以便迷惑的用户能够提出问题得到反馈或得到更多信息。否则，请使用 details 字段来扩展错误消息。 错误详情 Google API 为错误详情定义了一组标准错误负载，可以去 google/rpc/error_details.proto 查看。这里包含了 API 中最常见的错误，例如达到资源限额和错误的输入参数。与错误码相同，错误详情也应该使用标准的负载。 只有在能够帮助程序代码处理错误时才可以为错误详情引入新的类型。如果错误信息只能够由人（非代码）处理，应当让开发者依赖错误消息的内容来手动处理，而不是引入新的错误详情类型。如果新的类型被引入，一定要为它们进行显式的注册。 这里有一些 error_details 负载的示例： RetryInfo 描述了当客户端能够重试请求时，可能返回 Code.UNAVAILABLE 或 Code.ABORTED QuotaFailure 描述了配额检查失败的原因，可能返回 Code.RESOURCE_EXHAUSTED BadRequest 描述了客户端的非法请求，可能返回 Code.INVALID_ARGUMENT HTTP 映射 虽然 proto3 有原生的 JSON 编码，但 Google 的 API 平台使用如下的 JSON 格式进行错误响应，以允许向后兼容： 1234567891011&#123; &quot;error&quot;: &#123; &quot;code&quot;: 401, &quot;message&quot;: &quot;Request had invalid credentials.&quot;, &quot;status&quot;: &quot;UNAUTHENTICATED&quot;, &quot;details&quot;: [&#123; &quot;@type&quot;: &quot;type.googleapis.com/google.rpc.RetryInfo&quot;, ... &#125;] &#125;&#125; 字段 描述 error 为了向后兼容 Google API 客户端库添加的额外层 code Status.code 映射为 HTTP 状态码 message 对应 Status.message status 对应 Status.code details 对应 Status.details RPC 映射 不同的 RPC 协议用不同的方法映射到错误模型（error model）。对于 gRPC，生成的代码和所有语言的运行库都原生支持错误模型。你可以去 gRPC 的 API 文档中查看详情。 客户端库的映射 Google 客户端库可能会选择按照不同的惯例来对不同语言进行不同的错误处理。例如，库 google-cloud-go 会返回 google.rpc.Status 的实例，而 google-cloud-java 则会抛出异常。 错误信息本地化 google.rpc.Status 中的 message 字段是面向开发者的，必须（must） 是英语。 如果需要向用户提供错误信息，请使用 google.rpc.LocalizedMessage作为详情字段。google.rpc.LocalizedMessage 可以被本地化，但请保证 google.rpc.Status 中是英文。 API 服务应该默认使用认证用户的 locale 或 HTTP Accept-Language 头来决定本地化语言。 错误处理 下表包含了所有在 google.rpc.Code 中定义的 gRPC 错误代码和产生原因的简单描述。可以通过查看返回状态码的描述并修改对应的代码来处理错误。 | HTTP | RPC | Description | | - | - | | 200 | OK | 没有错误 | | 400 | INVALID_ARGUMENT | 客户端使用了错误的参数，通过 error message 和 error details 查看更多信息 | | 400 | FAILED_PRECONDITION | 当前的系统状态不能执行请求，例如删除非空目录 | | 400 | OUT_OF_RANGE | 客户端指定无效范围 | | 401 | UNAUTHENTICATED | 由于缺少、无效或过期的 OAuth 令牌，请求未通过身份验证 | | 403 | PERMISSION_DENIED | 客户端没有足够的权限，这可能是因为 OAuth 令牌没有正确的范围，客户端没有权限或者 API 还没有开放 | | 404 | NOT_FOUND | 指定的资源不存在，或者由于未公开的原因（如白名单）请求被拒绝 | | 409 | ABORTED | 并发冲突，例如读写冲突 | | 409 | ALREADY_EXISTS | 客户端试图创建的资源已经存在 | | 429 | RESOURCE_EXHAUSTED | 超过资源限额或频率限制,客户端应该通过 google.rpc.QuotaFailure 查看更多信息 | | 499 | CANCELLED | 客户端取消请求 | | 500 | DATA_LOSS | 不可恢复的数据丢失或损坏，客户端应该将此错误报告给用户 | | 500 | UNKNOWN | 服务端未知错误，一般是 BUG | | 500 | INTERNAL | 服务端内部错误，一般是 BUG | | 501 | NOT_IMPLEMENTED | 服务端未实现此 API | | 503 | UNAVAILABLE | 服务端不可用，一般是服务端挂了 | | 504 | DEADLINE_EXCEEDED | 请求超过最后期限，如果重复发生，请考虑减少请求的复杂性 | 错误重试 当发生 500，503 和 504 错误时客户端 应该（should） 以指数级增长的间隔来重试请求。除非文档中进行了说明，最小的重试间隔应该是 1 秒。对于 429 错误，客户端应该以最小 30 秒的间隔重试。对于其他错误，重试操作可能并不可行，请先确保请求是幂等的并查看错误消息以获得指引。 错误传播 如果 API 服务依赖于其他服务，则不应盲目地将这些服务中的错误传播给客户端。翻译错误时，有如下建议： 隐藏实现细节和机密信息 调整负责该错误的一方。例如，应把从其他服务接收到 INVALID ARGUMENT 错误转换为 INTERNAL 返回给调用者。 生成错误 服务端产生的错误应该包含足够多的信息来帮助客户端开发者理解和解决问题。同时也要小心用户数据的安全和隐私，因为错误经常会被作为日志记录下来并被其他人查看，所以应避免在错误信息和错误详情中暴露敏感信息。例如，错误信息“Client IP address is not on whitelist 128.0.0.0/8”将用户不可访问的服务端策略暴露出去了。 为了生成合适的错误，你首先应该熟悉 google.rpc.Code 来为每种错误条件选择最合适的错误。服务端程序可以并行检查多个错误条件，然后返回第一个。 下表列出了每一种错误码和对应的错误信息示例。 HTTP RPC 错误信息示例 400 INVALID_ARGUMENT Request field x.y.z is xxx, expected one of [yyy, zzz]. 400 FAILED_PRECONDITION Resource xxx is a non-empty directory, so it cannot be deleted. 400 OUT_OF_RANGE Parameter ‘age’ is out of range [0, 125]. 401 UNAUTHENTICATED Invalid authentication credentials. 403 PERMISSION_DENIED Permission ‘xxx’ denied on file ‘yyy’. 404 NOT_FOUND Resource ‘xxx’ not found. 409 ABORTED Couldn’t acquire lock on resource ‘xxx’. 409 ALREADY_EXISTS Resource ‘xxx’ already exists. 429 RESOURCE_EXHAUSTED Quota limit ‘xxx’ exceeded. 499 CANCELLED Request cancelled by the client. 500 DATA_LOSS 请看提示 500 UNKNOWN 请看提示 500 INTERNAL 请看提示 501 NOT_IMPLEMENTED Method ‘xxx’ not implemented. 503 UNAVAILABLE 请看提示 504 DEADLINE_EXCEEDED 请看提示 提示：因为客户端不能修复服务端的错误，生成额外的错误详情并没有用处。为了避免通过 error condition 泄露敏感信息，推荐不要生成任何 error message 并且只生成 google.rpc.DebugInfo 错误详情。DebugInfo 只能用于服务端日志，不要发送给客户端。 google.rpc 定义了一组标准错误负载，它们优先于自定义的错误负载。下表列出了每个错误代码及其匹配的标准错误负载。 HTTP RPC 推荐的错误详情 400 INVALID_ARGUMENT google.rpc.BadRequest 400 FAILED_PRECONDITION google.rpc.PreconditionFailure 400 OUT_OF_RANGE google.rpc.BadRequest 401 UNAUTHENTICATED 403 PERMISSION_DENIED 404 NOT_FOUND 409 ABORTED 409 ALREADY_EXISTS 429 RESOURCE_EXHAUSTED google.rpc.QuotaFailure 499 CANCELLED 500 DATA_LOSS 500 UNKNOWN 500 INTERNAL 501 NOT_IMPLEMENTED 503 UNAVAILABLE 504 DEADLINE_EXCEEDED 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－标准字段]]></title>
    <url>%2F2017%2F03%2Fgoogle-api-design-guide%2Fstandard-fields%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Standard Fields 本节介绍了在需要类似概念时应使用的一组标准消息字段定义，这将确保相同的概念在不同的 API 中具有相同的名称和语义。 名称 类型 描述 name string name 字段应该包含相对资源名称 parent string 对于资源定义和 List/Create 请求，parent 字段应该包含父资源的相对资源名称 create_time Timestamp 资源创建的时间戳 update_time Timestamp 资源最后更新的时间戳（当执行 create/patch/delete 操作时更新） delete_time Timestamp 资源删除的时间戳，只有支持恢复时有效 time_zone string 时区名，必须是一个像 “America/Los_Angeles” 的 IANA TZ 名字。更多信息请参考 https://en.wikipedia.org/wiki/List_of_tz_database_time_zones region_code string 国家地区编码（CLDR），更多信息请参考 http://www.unicode.org/reports/tr35/#unicode_region_subtag language_code string BCP-47 语言编码例如“en-US”或“sr-Latn”，更多信息请参考 http://www.unicode.org/reports/tr35/#Unicode_locale_identifier display_name string 资源的显示名称 title string 资源的官方名称，例如公司名称。它应该被看做是 display_name 的正式名称 description string 资源的描述信息 filter string List 方法的标准过滤字段 query string 在 search 方法中使用，功能与 filter 相同 page_token string List 请求中的分页字段 page_size int32 List 请求中一页的大小 total_size int32 资源总数量 next_page_token string List 响应中的下一页，用于下一次请求的 page_token 字段 resume_token string 用于恢复流请求的 opaque token labels map&lt;string, string&gt; 表示云资源标签 deleted bool 如果资源支持恢复，它必须具有 deleted 标签来标记资源是否被删除 show_deleted bool 如果资源支持恢复，对应的 List 方法必须有 show_deleted 字段来表示是否展示被删除的资源 update_mask FieldMask 用于在 Update 请求中对资源进行部分更新 validate_only bool 为 true 时表示请求只验证而不会执行 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－自定义方法]]></title>
    <url>%2F2017%2F03%2Fgoogle-api-design-guide%2Fcustom-methods%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Custom Methods 此篇文章讨论如何在 API 设计中使用自定义方法。 自定义方法指五个标准方法之外的 API 方法。应该（should） 只有当标准方法不能完成需要的功能时才使用自定义方法。一般情况下，API 设计者 应该（should） 在可行的情况下选择标准方法。标准方法有更简洁和明确定义的语义并且被大多数开发者熟知，所以它们更易于使用并且不易出错。另一个优势是 API 平台对标准方法的支持更好，比如计费、错误处理、日志和监控。 自定义方法可以被关联到资源、集合或服务。它 可以（may） 接收任意请求并返回任意响应，并且也可以支持流式请求与响应。 HTTP 映射 自定义方法 应该（should） 使用如下的通用映射方法： 1https://service.name/v1/some/resource/name:customVerb 使用 : 代替 / 来分隔资源名与自定义动词是为了支持任意 path 参数，例如，取消删除（undelete）文件能映射为 POST /files/a/long/file/name:undelete。 选择 HTTP 映射时 必须（shall） 遵守如下指南： 自定义方法 应该（should） 使用 HTTP POST 动词，因为 POST 有更加灵活的语义 自定义方法 不应该（should not） 使用 HTTP PATCH，但 可以（may） 使用其它 HTTP 动词。这种情况下，方法必须（must） 遵循该动词的标准 HTTP 语义 注意，使用 HTTP GET 的自定义方法 必须（must） 是幂等的并且不能有副作用。例如，在资源上实现特殊查询的自定义方法应该使用 HTTP GET。 自定义方法中待操作的资源或集合名 应该（should） 映射到 URL path 参数 URL path 必须（must） 以冒号加上自定义动词做为后缀 如果自定义方法使用的 HTTP 动词允许 HTTP 请求体（POST、PUT、PATCH或自定义的 HTTP 动词），这些自定义方法的 HTTP 配置 必须（must） 使用 body: &quot;*&quot; 并且所有剩余的请求信息 必须（shall） 映射到 HTTP 请求体中 如果自定义方法使用的 HTTP 动词不允许 HTTP 请求体（GET、DELETE），这些方法的 HTTP 配置 一定不要（must not） 使用 body，所有剩余的请求信息 必须（shall） 映射到 HTTP query 参数中 警告：如果服务实现多个 API，必须（must） 小心地创建服务配置以避免 API 间的自定义动词冲突。 1234567891011121314151617181920212223242526272829303132// 服务级别的自定义方法rpc Watch(WatchRequest) returns (WatchResponse) &#123; // 自定义方法映射到 HTTP POST，所有参数放到请求体中 option (google.api.http) = &#123; post: &quot;/v1:watch&quot; body: &quot;*&quot; &#125;;&#125;// 集合级别的自定义方法rpc ClearEvents(ClearEventsRequest) returns (ClearEventsResponse) &#123; option (google.api.http) = &#123; post: &quot;/v3/events:clear&quot; body: &quot;*&quot; &#125;;&#125;// 资源级别的自定义方法rpc CancelEvent(CancelEventRequest) returns (CancelEventResponse) &#123; option (google.api.http) = &#123; post: &quot;/v3/&#123;name=events/*&#125;:cancel&quot; body: &quot;*&quot; &#125;;&#125;// 用于批量 get 的自定义方法rpc BatchGetEvents(BatchGetEventsRequest) returns (BatchGetEventsResponse) &#123; // 批量 get 方法映射到 HTTP GET option (google.api.http) = &#123; get: &quot;/v3/events:batchGet&quot; &#125;;&#125; 用例 一些可选择自定义方法的其他情况： 重启虚拟机 设计的备选方案可以是“在重启资源集合中创建一个重启资源”（过于复杂）或者“虚拟机具有可变的状态，客户端能够将其从运行中改变为重启中”（会引入更多问题，比如是否有其他状态间的转变）。此外，重启是一个被熟知的概念，能够很好地转换为满足开发者需求的自定义方法 发送邮件 创建邮件信息并不一定要将它发送出去（草稿）。相对于备选方案（将消息移动到 Outbox 集合），自定义方法的优点是可以被 API 用户更多地发现并且更直接地理解它的概念 员工晋级 如果使用标准的 update 来实现，客户端必须重复进行管理流程的策略来保证正确的晋级 一些标准方法比自定义方法更好的例子： 使用不同的参数查询资源（使用标准的 list 方法和过滤） 简单的资源修改（使用带有字段掩码的标准 update 方法） 撤消通知（使用标准的 delete 方法） 通用自定义方法 常用的自定义方法名称列表如下。 API 设计者在引入自已的名称之前应该考虑这些名称，以便于跨 API 的一致性 方法名 自定义动词 HTTP 动词 备注 Canecl :cancel POST 取消未完成的操作（构建、计算等） BatchGet&lt;复数名词&gt; :batchGet POST 批量取得多个资源（详情请查看 List 的描述） Move :move GET 将资源从一个父资源移动到另一个中 Search :search GET 用于获取不符合 List 语义的数据 Undelete :undelete POST 恢复以前删除的资源，推荐的保留期为30天 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－标准方法]]></title>
    <url>%2F2017%2F03%2Fgoogle-api-design-guide%2Fstandard-methods%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Standard Methods 此章节定义标准方法 List、Get、Create、Update 和 Delete。标准方法存在的意义是广泛的 API 中许多 API 方法具有非常相似的语义，通过将这些类似的 API 融合到标准方法中，我们可以显著降低复杂性并提高一致性。以 Google APIs 为例，超过 70% 是标准方法，这让它们更加易于学习和使用。 下表描述了如何将它们映射为 REST 方法，也称为 CRUD 方法： 方法 HTTP 映射 HTTP 请求体 HTTP 响应体 List GET &lt;集合 URL&gt; 空 资源[1]列表 Get GET &lt;资源 URL&gt; 空 资源[1] Create POST &lt;集合 URL&gt; 资源 资源[1] Update PUT 或 PATCH &lt;资源 URL&gt; 资源 资源[1] Delete DELETE &lt;资源 URL&gt; 空 空[2] [1] List、Get、Create 和 Update方法支持字段掩码时，返回的资源 可能（may） 只包含部分数据。在某些情况下，API 平台会对所有方法原生支持字段掩码。 [2] 不立即删除资源（比如通过更新标志位或会执行时间较长的删除操作）的 Delete 方法返回的响应 应该（should） 包含长时间运行的操作或被修改的资源。 标准方法也 可以（may） 为不能在一个 API 调用周期完成的请求返回长期运行的操作。 下面章节详细描述了每一个标准方法。这些例子展示了在 .proto 文件中定义的方法，其中包含用于 HTTP 映射的特殊注释。你可以在 Google APIs 项目中找到许多使用标准方法的例子。 List List 方法接收资源名和零个或多个其它参数做为输入，返回符合输入的资源列表。它也通常被用来搜索资源。 List 适合取得没有缓存且大小有限的来自单个集合的数据。对于更广泛的情况，应该（should） 使用自定义方法。 应该使用自定义的 BatchGet 方法来实现批量获取（例如接收多个资源 ID然后返回对应的资源），而不是使用 List。但如果已存在能够提供同样功能的 List 方法，你 可以（may） 为此目的重用 List 方法。如果你在使用自定义的 BatchGet 方法，应该（should） 将它映射成 HTTP GET。 适用的常见模式：分页、结果排序 适用的命名约定：过滤字段、结果字段 HTTP 映射： List 方法 必须（must） 使用 HTTP GET 动词。 应该（should） 把要列出集合的资源名字放在 URL path 参数中。如果集合名映射到 URL path 中，URL 模版的最后一段（集合 ID） 必须（must） 是常量。 所有其他的请求信息字段 必须（shall） 映射到 URL 的 query 参数中。 没有请求体，API 配置中一定不能（must not） 定义 body。 响应体 应该（should） 包含资源列表和可选的元数据。 123456789101112131415161718192021222324252627// 列出指定书架上的所有图书rpc ListBooks(ListBooksRequest) returns (ListBooksResponse) &#123; // List 方法映射为 HTTP GET option (google.api.http) = &#123; // `parent` 获取父资源名，例如 &quot;shelves/shelf1&quot; get: &quot;/v1/&#123;parent=shelves/*&#125;/books&quot; &#125;;&#125;message ListBooksRequest &#123; // 父资源名称，例如 &quot;shelves/shelf1&quot;. string parent = 1; // 返回值的最大条数 int32 page_size = 2; // 从上一个 List 请求返回的 next_page_token 值（如果存在） string page_token = 3;&#125;message ListBooksResponse &#123; // 字段名应该匹配方法名中的名词 &quot;books&quot;，根据请求中的 page_size 字段，将会返回最大数量的条目 repeated Book books = 1; // 用于取得下一页结果的值，没有时为空 string next_page_token = 2;&#125; Get GET 方法接收资源名，零个或多个参数，返回指定的资源。 HTTP 映射： Get 方法 必须（must） 使用 HTTP GET 动词。 表示资源名的请求信息字段 应该（should） 映射到 URL path 参数中。 所有其他的请求信息字段 必须（shall） 映射到 URL 的 query 参数中。 没有请求体，API 配置中一定不能（must not） 定义 body。 返回的资源 必须（shall） 填充整个响应体。 12345678910111213// 取得指定的 bookrpc GetBook(GetBookRequest) returns (Book) &#123; // Get 映射为 HTTP GET。资源名映射到 URL 中。没有请求体 option (google.api.http) = &#123; // 注意 URL 中用于获取资源名的模板变量，例如 &quot;shelves/shelf1/books/book2&quot; get: &quot;/v1/&#123;name=shelves/*/books/*&#125;&quot; &#125;;&#125;message GetBookRequest &#123; // 此字段包含被请求资源的名字，例如：&quot;shelves/shelf1/books/book2&quot; string name = 1;&#125; Create Create 方法接收一个集合名、零个或多个参数，在指定集合中创建一个新的资源并将其返回。 如果 API 支持创建资源，它 应该（should） 在所有可被创建的资源上具有 Create 方法 。 HTTP 映射： Create 方法 必须（must） 使用 HTTP POST 动词。 请求消息中 应该（should） 含有名为 parent 的字段来接收新建资源的父资源名。 所有其他的请求信息字段 必须（shall） 映射到 URL 的 query 参数中。 请求 可以（may） 包含名为 &lt;resource&gt;_id 的字段名来允许调用者选择一个客户端分配的 ID。这个字段 必须（must） 映射到 URL query 参数中。 包含资源的请求信息字段 应该（should） 映射到请求体中。如果 Create 方法使用了 HTTP 配置中的 body 字段，那么 必须（must） 使用 body: &quot;&lt;resource_field&gt;&quot; 这种格式。 返回的资源 必须（shall） 填充到整个响应体。 如果 Create 方法支持客户端指定资源名，当资源名已存在时请求 应该（should） 失败（推荐（recommended） 使用 google.rpc.Code.ALREADY_EXISTS）或者服务端分配另外的名字，并且文档中应该明确指出创建的资源名可能会与传入的名字不同。 12345678910111213141516171819202122232425262728293031rpc CreateBook(CreateBookRequest) returns (Book) &#123; // Create 映射为 HTTP POST，URL path 做为集合名称 // HTTP 请求体中包含资源 option (google.api.http) = &#123; // 通过 `parent` 获取父资源名，例如 &quot;shelves/1&quot; post: &quot;/v1/&#123;parent=shelves/*&#125;/books&quot; body: &quot;book&quot; &#125;;&#125;message CreateBookRequest &#123; // 将被创建的 book 的父资源名 string parent = 1; // book 使用的 ID string book_id = 3; // 资源 book 将被创建，字段名应该与方法名中的名词相匹配 Book book = 2;&#125;rpc CreateShelf(CreateShelfRequest) returns (Shelf) &#123; option (google.api.http) = &#123; post: &quot;/v1/shelves&quot; body: &quot;shelf&quot; &#125;;&#125;message CreateShelfRequest &#123; Shelf shelf = 1;&#125; Update Update 方法接收包含资源和零个或多个参数的请求，更新指定的资源和属性并返回更新后的资源。 可修改的资源属性 应该（should） 使用 Update 方法来更新，除非属性中包含资源名或父资源。任何重命名或移动资源的操作 一定不要（must not） 通过 Update 执行，必须（shall） 通过自定义方法处理。 HTTP 映射： 标准的 Update 方法 应该（should） 支持资源的部分更新，使用带有名为 update_mask 的 FieldMask 字段的 HTTP 动词 PATCH 来执行操作。 应该（should） 使用自定义方法来实现更高级的 Update 方法，例如追加重复的字段。 如果 Update 方法仅支持资源的完整更新，则 必须（must） 使用 HTTP 动词 PUT实现。然而并不鼓励这样做，因为当添加新的资源字段时会有后向兼容的问题。 被修改资源的名称字段 必须（must） 映射到 URL path 参数中。此字段也 可以（may） 加在资源信息中。 包含资源的请求信息 必须（must） 映射到请求体中。 所有其他请求信息 必须（must） 映射到 URL query 参数中。 返回响应中的资源信息 必须（must） 是被修改的资源。 如果 API 接收客户端分配的资源名，那么服务端 可以（may） 允许客户端指定一个不存在的资源名来创建新的资源。否则，Update 方法应该（should） 因为不存在的资源名而失败。当资源名不存在是唯一错误时，应该（should） 使用错误码 NOT_FOUND。 即使 API 的 Update 方法能够新建资源，它也 应该（should） 提供 Create 方法。这是因为只有 Update 方法能够新建资源会让人迷惑。 123456789101112131415161718rpc UpdateBook(UpdateBookRequest) returns (Book) &#123; // Update 映射为 HTTP PATCH。资源名映射到 URL path 参数中 // 资源包含在 HTTP 请求体中 option (google.api.http) = &#123; // 注意用于获取待更新 book 的资源名的 URL 模版变量 patch: &quot;/v1/&#123;book.name=shelves/*/books/*&#125;&quot; body: &quot;book&quot; &#125;;&#125;message UpdateBookRequest &#123; // 替换服务端上的 book 资源 Book book = 1; // 用于资源更新的掩码 // `FieldMask` 的定义请参考 https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#fieldmask FieldMask update_mask = 2;&#125; Delete Delete 方法接收资源名和零个或多个参数，然后删除或准备删除指定资源。Delete 方法 应该（should） 返回 google.protobuf.Empty。 注意，API 不应该（should not） 依赖 Delete 方法返回的任何信息，因为它不能重复调用。 HTTP 映射： Delete 方法 必须（must） 使用 HTTP DELETE 动词 表示资源名的请求信息字段 应该（should） 映射到 URL path 参数中 所有其他的请求信息字段 必须（shall） 映射到 URL 的 query 参数中 没有请求体，API 配置 一定不要（must not） 定义 body Delete 方法直接删除资源时，应该（should） 返回空的响应 Delete 方法初始化一个长时间的操作时，应该（should） 返回这个操作 Delete 方法将资源标记为被删除时，应该（should） 返回更新后的资源 Delete 方法的调用在效果上应该是幂等的，但并不需要有相同的返回值。任意次 Delete 请求的结果 应该（should） 是资源被删除，但只有第一次请求应该返回正确，后续的请求应该返回 google.rpc.Code.NOT_FOUND。 12345678910111213rpc DeleteBook(DeleteBookRequest) returns (google.protobuf.Empty) &#123; // Delete 映射为 HTTP DELETE。资源名映射到 URL path 参数中 // 没有请求体 option (google.api.http) = &#123; // 注意 URL 模板变量获取待删除资源的名称，例如 &quot;shelves/shelf1/books/book2&quot; delete: &quot;/v1/&#123;name=shelves/*/books/*&#125;&quot; &#125;;&#125;message DeleteBookRequest &#123; // 待删除的资源名称，例如 &quot;shelves/shelf1/books/book2&quot; string name = 1;&#125; 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－资源名称]]></title>
    <url>%2F2017%2F03%2Fgoogle-api-design-guide%2Fresource-names%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Resource Names 在面向资源的 API 中，资源是命名实体，资源名称是其标识符。每个资源 必须（ MUST ） 有唯一的资源名称。资源名称由资源自己的 ID，任一父资源的 ID 及其 API 服务名称组成。下面我们将看一看资源 ID 和资源名是如何构成的。 gRPC API 应该为资源名使用无协议（scheme-less）的 URI。它们通常遵循 REST URL 惯例并且其行为与网络文件路径非常相似。它们能非常容易地映射到 REST API：详细内容查看标准方法。 集合是一种特殊类型的资源，它包含了相同类型子资源的列表。例如，目录是文件资源的集合。集合的资源 ID 叫做集合 ID。 资源名称由集合 ID 和资源 ID 按层次组织形成，并以斜杠（/）分隔。如果资源包含子资源，子资源名称的格式是父资源名称后面加上子资源 ID，同样地使用斜杠分隔。 例 1：一个存储服务具有 buckets 集合，每个 bucket 具有 objects 集合： API 服务名 集合 ID 资源 ID 集合 ID 资源 ID //storage.googleapis.com /buckets /bucket-id /objects /object-id 例 2：一个具有 users 集合的邮件服务，每个用户具有 settings 子资源， settings 子资源具有 customFrom 和另外的子资源： API 服务名 集合 ID 资源 ID 资源 ID 资源 ID //mail.googleapis.com /users /name@example.com /settings /customFrom API 设计者可以为资源和集合 ID 选择任何可接受的值，只要它们在资源层次结构中是唯一的即可。你可以在下面找到有关选择适当资源和集合 ID 的更多指南。 完整资源名 无协议（scheme-less） URI 由兼容 DNS 的 API 服务名和资源路径组成。资源路径也称为相对资源名。例如： 1&quot;//library.googleapis.com/shelves/shelf1/books/book2&quot; API 服务名用于客户端定位 API 服务端点，如果只为内部服务，它**可以（may）**是假的 DNS 名。如果 API 服务名在上下文中显而易见的话则会经常使用相对资源名。 相对资源名 没有斜杠（/）开头的 URI 路径标识了 API 服务中的资源。例如： 1&quot;shelves/shelf1/books/book2&quot; 资源 ID 使用非空的 URI 段标识其父资源中的资源。请看上面的例子。 资源名称后面跟随的资源 ID 可以（may） 具有不只一个 URI 段，例如： 集合 ID 资源 ID files /source/py/parser.py 如果可以的话，API 服务**应该（should）**使用 URL 友好的资源 ID。资源 ID 必须（must） 明确地记录在文档中，不管它们是由客户端还是服务端分配的。例如，文件名一般由客户端分配，而邮件信息 ID 一般由服务端分配。 集合 ID 使用非空的 URI 段标识其父资源中的资源集合。请看上面的例子。 因为集合 ID 经常出现在生成的客户端库中，它们 必须（must） 符合以下要求： 必须（must） 是合法的 C/C++ 标识符 必须（must） 是复数形式的首字母小写的驼峰命名 必须（must） 使用清晰简明的英语词汇 应该（should） 避免或限定过于笼统的术语。例如：RowValue 优于 Value。除非明确定义，否则 应该（should） 避免使用如下术语： Element Entry Instance Item Object Resource Type Value 资源名 vs URL 完整的资源名类似普通的 URL，但它们并不相同。同样的资源能够通过不同版本或不同协议的 API 来暴露出去。完整的资源名并没有指定这些信息，所以必须将它映射到特定的协议和 API 版本上才能直接地使用。 为了通过 REST API 使用完整的资源名，必须（must） 使用如下方法将其映射为 REST URL：在服务名前添加 HTTPS 协议、在资源路径前添加 API 主版本号、将资源路径进行 URL 转义。例如： 12345// 这是日历事件的资源名&quot;//calendar.googleapis.com/users/john smith/events/123&quot;// 这是对应的 HTTP URL&quot;https://calendar.googleapis.com/v3/users/john%20smith/events/123&quot; 资源名做为字符串 除非有向后兼容的问题，Google API 必须（must） 使用字符串来表示资源名。资源名 应该(should) 像普通文件路径那样处理，并且不支持百分号编码。 对于资源定义，第一个字段 应该（should） 是资源名称的字符串字段，它 应该（should） 叫作 name。 注意：像 display_name、first_name、last_name、full_name 这种与名字相关的字段 应该（should） 给出定义来避免混乱。 例子： 12345678910111213141516171819202122232425262728293031323334service LibraryService &#123; rpc GetBook(GetBookRequest) returns (Book) &#123; option (google.api.http) = &#123; get: &quot;/v1/&#123;name=shelves/*/books/*&#125;&quot; &#125;; &#125;; rpc CreateBook(CreateBookRequest) returns (Book) &#123; option (google.api.http) = &#123; post: &quot;/v1/&#123;parent=shelves/*&#125;/books&quot; body: &quot;book&quot; &#125;; &#125;;&#125;message Book &#123; // book 的资源名。必须是&quot;shelves/*/books/*&quot;的格式 // 例如：&quot;shelves/shelf1/books/book2&quot;. string name = 1; // ... 其他属性&#125;message GetBookRequest &#123; // 一个 book 的资源名。例如：&quot;shelves/shelf1/books/book2&quot; string name = 1;&#125;message CreateBookRequest &#123; // 创建 book 的父资源名 // 例如：&quot;shelves/shelf1&quot; string parent = 1; // 被创建的 book 资源。客户端一定不能（must not）设置 `Book.name` 字段 Book book = 2;&#125; 提示：为了资源名称的一致性，开始的斜杠 一定不能（must not） 被 URL 模版变量捕获。例如，必须（must） 使用 URL 模版 &quot;/v1/{name=shelves/*/books/*}&quot; 而不是 &quot;/v1{name=/shelves/*/books/*}&quot;。 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－面向资源的设计]]></title>
    <url>%2F2017%2F03%2Fgoogle-api-design-guide%2Fresource-oriented-design%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide - Resource Oriented Design 这篇设计指南的目的是帮助开发者设计出简单、一致、易于使用的网络 API，同时它也帮助我们统一了 RPC API（基于 socket）与 REST API（基于 HTTP）的设计。 传统上，人们参考像 CORBA 和 Windows COM 这样的 API 接口和方法来设计 RPC API。随着时间推移，越来越多的接口和方法被添加。最后的结果是被数量众多的接口和方法淹没，每一个都和其他不同。为了正确使用它们开发者必须仔细学习每一个接口或方法，这必定会消耗时间并容易引入问题。 REST 架构风格最早出现于2000年，主要设计为与 HTTP/1.1 一起使用。它的主要原则是定义能够被少量方法操作的命名资源。资源和方法被认为是 API 的名词和动词。与 HTTP 协议配合，资源名自然地映射为 URL，方法自然地映射为 HTTP 方法 POST、GET、PUT、PATCH 和 DELETE。 HTTP REST API 在互联网领域已经取得了巨大成功。在2010年，约 74% 的网络 API 是 HTTP REST API。 虽然 HTTP REST API 在互联网特别流行，但它们承载的流量却比传统的 RPC API 要少。例如，在美国高峰时期的约一半流量是视频内容，但因为效率问题，很少有人会考虑使用 REST API 来传输这些内容。在数据中心，许多公司使用基于 socket 的 RPC API 来传输大部分网络流量，这会比 REST API 高出几个数量级。 实际上，由于种种原因 RPC API 和 HTTP REST API 都是需要的。理想情况下一个 API 平台应该为所有 API 提供最好的支持。此指南将会帮助你设计并实现符合这一原则的 API。它将面向资源的设计原则应用到一般的 API 设计中，并且定义了许多通用的设计模式来提升可用性并降低复杂性。 注意：此设计指南解释了如何在独立于编程语言、操作系统或者网络协议的 API 设计中应用 REST 原则，而不是仅用于创建 REST API 的指南 什么是 REST API？ REST API 被建模成可单独寻址的资源（API 的名词）的集合。资源通过它们的资源名来引用，通过一小组方法（也被称为动词）来操作。 REST Google API 的标准方法（也叫 REST 方法）是 List Get Create Update 和 Delete。当存在类似数据库事务这种不能被简单地映射到标准方法的需求时，API 设计者也可以使用自定义方法（也叫自定义动词或自定义操作）。 注意：自定义动词不表示创造自定义的 HTTP 动词来支持自定义方法。对于基于 HTTP 的API，简单地映射到最合适的 HTTP 动词即可。 设计流程 此设计指南建议采用如下步骤来设计面向资源的 API（更详细的内容请参考后面的小节） 确定 API 提供的资源类型 确定资源间的关系 依据类型和关系来确定资源名方案 确定资源结构 为资源添加最少的方法集 资源 面向资源的 API 通常以资源层次进行建模，每一个节点是一个简单的资源或资源集合。方便起见，通常将它们称为资源和集合。 集合包含具有相同类型的资源列表。例如一个用户拥有联系人的集合 资源拥有一些状态和 0 个或多个子资源。每一个子资源可以是简单资源或资源集合 例如，Gmail API 有用户的集合，每个用户有信息的集合、线程的集合、标签的集合、一个资料资源和一些设置项资源。 虽然存储系统和 REST API 之间存在一些概念上的一致性，但是具有面向资源的 API 的服务不一定是数据库，并且在解释资源和方法方面具有巨大的灵活性。例如，创建日历事件（资源）可以为参加会议者创建附加事件，向参加者发送邮件邀请，预约会议室和更新视频会议时间表。 方法 面向资源的 API 的关键特性是它通过对资源执行的方法（功能）来强调资源（数据模型）。一个典型的面向资源的 API 通过少量方法暴露大量资源。这些方法可以是标准方法也可以是自定义方法。对于本指南，标准方法是 List Get Create Update 和 Delete。 当一个 API 功能自然地映射到一个标准方法时，应该（should） 在API 设计中使用此方法。对于不能自然映射到标准方法的功能，可以(may) 使用自定义方法。自定义方法提供了与传统 RPC API 相同的设计自由度，能够用来实现常见的编程模式，例如数据库事务和数据分析。 例子 下面的部分列出了一些实际的例子，展示了如何将面向资源的 API 设计应用到大规模服务上。 Gmail API Gmail API 服务实现了 Gmail API 并提供了 Gmail 的大部分功能。它有以下资源模型： Gmail API 服务：gmail.googleapis.com 用户集合：users/*。每个用户有以下资源 消息集合：users/*/messages/* 线程集合：users/*/threads/* 标签集合：users/*/labels/* 修改历史集合：users/*/history/* 代表用户资料的资源：users/*/profile 代表用户设置项的资源：users/*/settings Google Cloud Pub/Sub API pubsub.googleapis.com 服务实现了Google Cloud Pub/Sub API，它定义了下面的资源模型： API 服务：pubsub.googleapis.com 话题集合：projects/*/topics/* 订阅集合：projects/*/subscriptions/* 注意：其他 Pub/Sub API 的实现可能会选择不同的资源名称方案 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－介绍]]></title>
    <url>%2F2017%2F03%2Fgoogle-api-design-guide%2Fintroduction%2F</url>
    <content type="text"><![CDATA[翻译自 API Design Guide 介绍 这是一篇网络 API 的通用设计指南，它从2014年开始被 Google 使用，并且指导我们设计了 Cloud API 和 其它Google API。我们将此指南分享出来希望能让人们更便捷地合作。 Google Cloud Endpoints 的开发者在设计gRPC API时可能会发现这篇指南特别有用，我们强烈推荐这类开发者使用这些设计原则，但我们不会要求非 Google 员工必须遵守。 此指南适用于 REST API 和 RPC API，特别是 gRPC API，gRPC API 使用 Protocol Buffers 来定义API接口，使用 API Service Configuration 来配置 API 服务，包括 HTTP 映射(HTTP mapping)、日志和监控。HTTP 映射功能被 Google API 和 Cloud Endpoints gRPC API 用来进行 JSON/HTTP 与 Protocol Buffers/RPC 的转换。 新的风格和设计被采纳和核准后将会被添加进来，所以此指南会持续更新。并且API设计的艺术与技术会一直进步，所以此指南永远不会“完结”。 约定 这些关键词&quot;MUST&quot;、“MUST NOT”、“REQUIRED”、“SHALL”、“SHALL NOT”、“SHOULD”、“SHOULD NOT”、“RECOMMENDED”、“MAY” 和 &quot;OPTIONAL&quot;的解释请参考 RFC 2119 或中文解释（翻译时我会保留这些单词并且加粗显示）。 查看其他章节]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 设计指南－目录]]></title>
    <url>%2F2017%2F03%2Fgoogle-api-design-guide%2Fcontents%2F</url>
    <content type="text"><![CDATA[下面的文章翻译自 Google API 设计指南，翻译时的版本是2017-02-21 介绍 面向资源的设计 资源名称 标准方法 自定义方法 标准字段 错误 命名约定 设计模式 文档 使用 proto3 版本控制 兼容性 目录结构 文件结构 词汇表]]></content>
      <tags>
        <tag>架构</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[alertmanager邮件模版]]></title>
    <url>%2F2017%2F03%2Falertmanager%E9%82%AE%E4%BB%B6%E6%A8%A1%E7%89%88%2F</url>
    <content type="text"><![CDATA[说明 alertmanager能够设置多种通知规则，这篇文章介绍如何配置邮件通知 简单设置 如下修改receivers-email_configs-html后，收到的邮件内容是：测试 http://ming:9093 。html表示的是邮件内容。 12345receivers:- name: &apos;mengyuan&apos; email_configs: - to: &apos;xxxx@xxx.com&apos; html: &apos;测试 &#123;&#123; .ExternalURL &#125;&#125;&apos; 模版变量 邮件模版使用go template编写，两对大括号中的.ExternalURL即表示变量的ExternalURL字段，Data结构如下，源码在这里。请自行google go template的使用方法。 12345678910111213141516171819202122232425262728// Data is the data passed to notification templates and webhook pushes.//// End-users should not be exposed to Go's type system, as this will confuse them and prevent// simple things like simple equality checks to fail. Map everything to float64/string.type Data struct &#123; Receiver string `json:"receiver"` Status string `json:"status"` Alerts Alerts `json:"alerts"` GroupLabels KV `json:"groupLabels"` CommonLabels KV `json:"commonLabels"` CommonAnnotations KV `json:"commonAnnotations"` ExternalURL string `json:"externalURL"`&#125;// Alert holds one alert for notification templates.type Alert struct &#123; Status string `json:"status"` Labels KV `json:"labels"` Annotations KV `json:"annotations"` StartsAt time.Time `json:"startsAt"` EndsAt time.Time `json:"endsAt"` GeneratorURL string `json:"generatorURL"`&#125;// Alerts is a list of Alert objects.type Alerts []Alert// KV is a set of key/value string pairs.type KV map[string]string 邮件模版文件 上面例子将html的值写为邮件模版，但实际情况一般需要我们在其他文件中定义好模版，在html中引用模版名字，go tempate的子模版功能可以满足我们的要求。 在templates下填写模版文件路径，html下引用定义好的子模版 12345678910# Files from which custom notification template definitions are read.# The last component may use a wildcard matcher, e.g. &apos;templates/*.tmpl&apos;.templates: [ - &lt;filepath&gt; ... ]receivers:- name: &apos;mengyuan&apos; email_configs: - to: &apos;xxx@xxx.com&apos; html: &apos;&#123;&#123; template &quot;email.mengyuan.html&quot; . &#125;&#125;&apos; headers: &#123; Subject: &quot;[WARN] 报警邮件test&quot; &#125; 模版文件mengyuan.tmpl 12345678&#123;&#123; define &quot;email.mengyuan.html&quot; &#125;&#125;&lt;table&gt; &lt;tr&gt;&lt;td&gt;报警名&lt;/td&gt;&lt;td&gt;开始时间&lt;/td&gt;&lt;/tr&gt; &#123;&#123; range $i, $alert := .Alerts &#125;&#125; &lt;tr&gt;&lt;td&gt;&#123;&#123; index $alert.Labels &quot;alertname&quot; &#125;&#125;&lt;/td&gt;&lt;td&gt;&#123;&#123; $alert.StartsAt &#125;&#125;&lt;/td&gt;&lt;/tr&gt; &#123;&#123; end &#125;&#125;&lt;/table&gt;&#123;&#123; end &#125;&#125; 测试时发现子模版名称有数字时（如email.mengyuan1.html）不会收到通知alermanager也不报错，可能是BUG。 配置好后，收到的邮件内容如下]]></content>
      <tags>
        <tag>prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[alertmanager报警规则详解]]></title>
    <url>%2F2017%2F03%2Falertmanager%E6%8A%A5%E8%AD%A6%E8%A7%84%E5%88%99%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[说明 这篇文章介绍prometheus和alertmanager的报警和通知规则，prometheus的配置文件名为prometheus.yml，alertmanager的配置文件名为alertmanager.yml 报警：指prometheus将监测到的异常事件发送给alertmanager，而不是指发送邮件通知 通知：指alertmanager发送异常事件的通知（邮件、webhook等） 报警规则 在prometheus.yml中指定匹配报警规则的间隔 12# How frequently to evaluate rules.[ evaluation_interval: &lt;duration&gt; | default = 1m ] 在prometheus.yml中指定规则文件（可使用通配符，如rules/*.rules） 123# Load rules once and periodically evaluate them according to the global &apos;evaluation_interval&apos;.rule_files: - rules/mengyuan.rules 在rules目录中添加mengyuan.rules 1234567891011121314151617ALERT goroutines_gt_70 IF go_goroutines &gt; 70 FOR 5s LABELS &#123; status = &quot;yellow&quot; &#125; ANNOTATIONS &#123; summary = &quot;goroutines 超过 70，当前值&#123;&#123; $value &#125;&#125;&quot;, description = &quot;当前实例 &#123;&#123; $labels.instance &#125;&#125;&quot;, &#125;ALERT goroutines_gt_90 IF go_goroutines &gt; 90 FOR 5s LABELS &#123; status = &quot;red&quot; &#125; ANNOTATIONS &#123; summary = &quot;goroutines 超过 90，当前值&#123;&#123; $value &#125;&#125;&quot;, description = &quot;当前实例 &#123;&#123; $labels.instance &#125;&#125;&quot;, &#125; 配置文件设置好后，需要让prometheus重新读取，有两种方法： 通过HTTP API向/-/reload发送POST请求，例：curl -X POST http://localhost:9090/-/reload 向prometheus进程发送SIGHUP信号 将邮件通知与rules对比一下（还需要配置alertmanager.yml才能收到邮件） 通知规则 设置alertmanager.yml的的route与receivers 123456789101112131415161718192021222324252627282930route: # The labels by which incoming alerts are grouped together. For example, # multiple alerts coming in for cluster=A and alertname=LatencyHigh would # be batched into a single group. group_by: [&apos;alertname&apos;] # When a new group of alerts is created by an incoming alert, wait at # least &apos;group_wait&apos; to send the initial notification. # This way ensures that you get multiple alerts for the same group that start # firing shortly after another are batched together on the first # notification. group_wait: 5s # When the first notification was sent, wait &apos;group_interval&apos; to send a batch # of new alerts that started firing for that group. group_interval: 1m # If an alert has successfully been sent, wait &apos;repeat_interval&apos; to # resend them. repeat_interval: 3h # A default receiver receiver: mengyuanreceivers:- name: &apos;mengyuan&apos; webhook_configs: - url: http://192.168.0.53:8080 email_configs: - to: &apos;mengyuan@tenxcloud.com&apos; 名词解释 Route route属性用来设置报警的分发策略，它是一个树状结构，按照深度优先从左向右的顺序进行匹配。 123// Match does a depth-first left-to-right search through the route tree// and returns the matching routing nodes.func (r *Route) Match(lset model.LabelSet) []*Route &#123; Alert Alert是alertmanager接收到的报警，类型如下。 1234567891011121314// Alert is a generic representation of an alert in the Prometheus eco-system.type Alert struct &#123; // Label value pairs for purpose of aggregation, matching, and disposition // dispatching. This must minimally include an "alertname" label. Labels LabelSet `json:"labels"` // Extra key/value information which does not define alert identity. Annotations LabelSet `json:"annotations"` // The known time range for this alert. Both ends are optional. StartsAt time.Time `json:"startsAt,omitempty"` EndsAt time.Time `json:"endsAt,omitempty"` GeneratorURL string `json:"generatorURL"`&#125; 具有相同Lables的Alert（key和value都相同）才会被认为是同一种。在prometheus rules文件配置的一条规则可能会产生多种报警 Group alertmanager会根据group_by配置将Alert分组。如下规则，当go_goroutines等于4时会收到三条报警，alertmanager会将这三条报警分成两组向receivers发出通知。 123456789ALERT test1 IF go_goroutines &gt; 1 LABELS &#123;label1=&quot;l1&quot;, label2=&quot;l2&quot;, status=&quot;test&quot;&#125;ALERT test2 IF go_goroutines &gt; 2 LABELS &#123;label1=&quot;l2&quot;, label2=&quot;l2&quot;, status=&quot;test&quot;&#125;ALERT test3 IF go_goroutines &gt; 3 LABELS &#123;label1=&quot;l2&quot;, label2=&quot;l1&quot;, status=&quot;test&quot;&#125; 主要处理流程 接收到Alert，根据labels判断属于哪些Route（可存在多个Route，一个Route有多个Group，一个Group有多个Alert） 将Alert分配到Group中，没有则新建Group 新的Group等待group_wait指定的时间（等待时可能收到同一Group的Alert），根据resolve_timeout判断Alert是否解决，然后发送通知 已有的Group等待group_interval指定的时间，判断Alert是否解决，当上次发送通知到现在的间隔大于repeat_interval或者Group有更新时会发送通知 TODO 重启对发送报警与通知的影响 能否组成集群 参考 https://github.com/prometheus/alertmanager/blob/master/template/email.html https://prometheus.io/blog/2016/03/03/custom-alertmanager-templates/ http://studygolang.com/articles/8023 http://www.admpub.com/blog/post-221.html]]></content>
      <tags>
        <tag>prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s-apiserver]]></title>
    <url>%2F2017%2F02%2Fk8s-apiserver%2F</url>
    <content type="text"><![CDATA[说明 apiserver对外提供API服务，主要功能是验证处理REST请求，并更新保存在etcd中的相关对象。这篇文章以kubernetes1.5.3进行说明。 代码学习 apiserver的入口是cmd/kube-apiserver/apiserver.go app.Run()的操作： 参数校验 加载插件 m, err := config.Complete().New()为httpserver设置路由 sharedInformers.Start(wait.NeverStop)启动informer，用于监听pods, nodes, namespaces等组件的事件 m.GenericAPIServer.PrepareRun().Run(wait.NeverStop)启动http server k8s设置对象的默认值：pkg/api/&lt;version&gt;/defaults.go 例： 1234567891011121314151617func SetDefaults_Container(obj *Container) &#123; if obj.ImagePullPolicy == "" &#123; // Ignore error and assume it has been validated elsewhere _, tag, _, _ := parsers.ParseImageName(obj.Image) // Check image tag if tag == "latest" &#123; obj.ImagePullPolicy = PullAlways &#125; else &#123; obj.ImagePullPolicy = PullIfNotPresent &#125; &#125; if obj.TerminationMessagePath == "" &#123; obj.TerminationMessagePath = TerminationMessagePathDefault &#125;&#125; 验证对象格式：pkg/api/validation/validation.go 123456789101112131415// ValidateHasLabel requires that api.ObjectMeta has a Label with key and expectedValuefunc ValidateHasLabel(meta api.ObjectMeta, fldPath *field.Path, key, expectedValue string) field.ErrorList &#123; allErrs := field.ErrorList&#123;&#125; actualValue, found := meta.Labels[key] if !found &#123; allErrs = append(allErrs, field.Required(fldPath.Child("labels").Key(key), fmt.Sprintf("must be '%s'", expectedValue))) return allErrs &#125; if actualValue != expectedValue &#123; allErrs = append(allErrs, field.Invalid(fldPath.Child("labels").Key(key), meta.Labels, fmt.Sprintf("must be '%s'", expectedValue))) &#125; return allErrs&#125; api url结构 prefix/group/version/… 例： /apis/extensions/v1beta1/deployments，prefix=apis group=extensions version=v1beta1 /api/v1，prefix=api group=&quot;&quot; version=v1 操作etcd 代码位置：pkg/storage，使用etcd客户端github.com/coreos/etcd/clientv3(v3)/github.com/coreos/etcd/client(v2) pkg/api/rest/rest.go 声明各个interface，在registerResourceHandlers中做断言 registerResourceHandlers()为path注册handler action path:namespaces/{namespace}/bindings, verb:POST action path:componentstatuses, verb:LIST action path:componentstatuses/{name}, verb:GET type APIGroupVersion 123type APIGroupVersion struct &#123; Storage map[string]rest.Storage ... Storage的key(string)是各资源的path，value(rest.Storage)是操作此path的对象 下面的函数从apiGroupInfo.VersionedResourcesStorageMap中取得storage 12345678910func (s *GenericAPIServer) getAPIGroupVersion(apiGroupInfo *APIGroupInfo, groupVersion unversioned.GroupVersion, apiPrefix string) (*apiserver.APIGroupVersion, error) &#123; storage := make(map[string]rest.Storage) for k, v := range apiGroupInfo.VersionedResourcesStorageMap[groupVersion.Version] &#123; storage[strings.ToLower(k)] = v &#125; version, err := s.newAPIGroupVersion(apiGroupInfo, groupVersion) version.Root = apiPrefix version.Storage = storage return version, err&#125; type APIGroupInfo APIGroupInfo.VersionedResourcesStorageMap保存group中各version的资源storage 123456// Info about an API group.type APIGroupInfo struct &#123; GroupMeta apimachinery.GroupMeta // Info about the resources in this group. Its a map from version to resource to the storage. VersionedResourcesStorageMap map[string]map[string]rest.Storage ... pkg/registry 代码中对这个包的说明是Package registry implements the storage and system logic for the core of the api server. 以pkg/registry/core/rest/storage_core.go为例说明 func (c LegacyRESTStorageProvider) NewLegacyRESTStorage(restOptionsGetter genericapiserver.RESTOptionsGetter) (LegacyRESTStorage, genericapiserver.APIGroupInfo, error)此函数中初始化资源与storage映射的map，部分代码： 1234567restStorageMap := map[string]rest.Storage&#123; "pods": podStorage.Pod, "pods/attach": podStorage.Attach, "pods/status": podStorage.Status, "pods/log": podStorage.Log, "pods/exec": podStorage.Exec, ... pkg/registry/core/pod/etcd/etcd.go的NewStorage()中变量storageInterface 1234567891011121314func (c completedConfig) New() (*Master, error) &#123; ... restOptionsFactory := restOptionsFactory&#123; deleteCollectionWorkers: c.DeleteCollectionWorkers, enableGarbageCollection: c.GenericConfig.EnableGarbageCollection, storageFactory: c.StorageFactory, &#125; if c.EnableWatchCache &#123; restOptionsFactory.storageDecorator = registry.StorageWithCacher &#125; else &#123; restOptionsFactory.storageDecorator = generic.UndecoratedStorage &#125; ... 12345678910// NewRawStorage creates the low level kv storage. This is a work-around for current// two layer of same storage interface.// TODO: Once cacher is enabled on all registries (event registry is special), we will remove this method.func NewRawStorage(config *storagebackend.Config) (storage.Interface, factory.DestroyFunc) &#123; s, d, err := factory.Create(*config) if err != nil &#123; glog.Fatalf("Unable to create storage backend: config (%v), err (%v)", config, err) &#125; return s, d&#125; storage.Interface pkg/storage/etcd/etcd_helper.go使用etcd v2 api，实现了storage.Interface pkg/storage/etcd3/store.go使用etcd v3 api，实现了storage.Interface 编解码etcd存储的数据 pkg/genericapiserver/storage_factory.go NewStorageCodec()生成Codec 参考 https://github.com/kubernetes/kubernetes/blob/release-1.5/docs/design/architecture.md https://kubernetes.io/docs/admin/kube-apiserver/ https://github.com/kubernetes/community/tree/master/contributors/design-proposals https://github.com/kubernetes/community/blob/master/contributors/devel/api-conventions.md https://github.com/kubernetes/community/blob/master/contributors/devel/api_changes.md https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-group.md]]></content>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA使用技巧收集]]></title>
    <url>%2F2017%2F01%2FIDEA%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[之前一直用vscode来写Golang，直到有人向我推荐了IDEA，便折服于它的强大。在这里分享一些IDEA的操作和技巧（只说Golang，但一些技巧对其他语言同样有效）。 Help -&gt; Keymap Reference能够打开快捷键映射的PDF文件，方便我们查看 在类型、函数、变量上CTRL + 鼠标左键能快速显示它们的使用位置，更好的一点是能够显示出对变量的读和写，这对阅读代码是很大的帮助。不过有一点需要注意，对变量取地址的操作也会判断为读 给struct添加json tag。在每个元素后连续ALT + SHIFT + 鼠标左键添加多个光标，输入反引号(`)和j，此时会弹出窗口，再按下TAB键，所有元素都会补全tag CTRL + SHIFT + I快速查看函数定义，不需要跳转到定义文件查看后再返回正在编辑的文件，这种感觉不能更爽 重构，快捷键SHIFT + F6 ALT + F1在工程栏中展开当前文件的位置 File Watchers插件，设置为当文件保存时调用gofmt等工具格式化代码，或做其他事情 我们经常要输入一些重复的代码，比如判断err是否为nil。通过Live Template解放双手吧（CTRL + J）]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker容器间通信的一种方法]]></title>
    <url>%2F2017%2F01%2Fdocker%E5%AE%B9%E5%99%A8%E9%97%B4%E9%80%9A%E4%BF%A1%E7%9A%84%E4%B8%80%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[以我的ghost博客为例进行说明，我在VPS上用docker启动了两个ghost博客，还有一个Nginx做反向代理，将两个域名分别指向两个博客。 docker启动命令 ghost: 12docker run -e NODE_ENV=production --name ghost1 -v /path/to/data/ghost/ghost1/:/var/lib/ghost -d ghostdocker run -e NODE_ENV=production --name ghost2 -v /path/to/data/ghost/ghost2/:/var/lib/ghost -d ghost nginx: 1docker run -p 80:80 --name nginx --link ghost1 --link ghost2 -v /path/to/data/nginx/nginx.conf:/etc/nginx/nginx.conf -d nginx 先启动两个ghost，然后启动nginx。使用–link参数将容器“链接”到一起，此参数会在容器中加入环境变量并在/etc/hosts中插入一条容器名与IP的映射 1234root@fabfd4bacfda:/# cat /etc/hosts172.17.0.3 ghost1 d19c0134011a172.17.0.5 ghost2 0e2e66ba70e0172.17.0.4 fabfd4bacfda 设置nginx反向代理 修改nginx.conf，在http段内添加如下内容 123456789101112131415161718192021222324252627http &#123; server &#123; listen 80; server_name www.domain1.tk domain1.tk; location / &#123; proxy_pass http://ghost1:2368; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; server &#123; listen 80; server_name www.domain2.tk domain2.tk; location / &#123; proxy_pass http://ghost2:2368; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;&#125; 注意proxy_pass的值proxy_pass http://ghost2:2368;。 ghost2是nginx容器/etc/hosts中的一条，是由–link参数添加进来的。 设置完这些后，nginx就会将两个域名的请求分别代理到两个博客中。 补充 容器重启后IP可能变化，所以直接在nginx.conf中指定IP并不是一个好方法。使用–link时hosts文件会随着容器IP的变化更新，所以使用域名才是更容易维护的方法。]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Go语言的slice]]></title>
    <url>%2F2017%2F01%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Go%E8%AF%AD%E8%A8%80%E7%9A%84slice%2F</url>
    <content type="text"><![CDATA[先看这段代码，结果是[0 2 3]，很多人都能答对。 12345678func modify(s []int) &#123; s[0] = 0&#125;func main() &#123; s := []int&#123;1, 2, 3&#125; modify(s) fmt.Println(s)&#125; 然后稍微改动一下，再猜一下结果 12345678func pop(s []int) &#123; s = s[:len(s)-1]&#125;func main() &#123; s := []int&#123;1, 2, 3&#125; pop(s) fmt.Println(s)&#125; 如果认为输出[1 2]的话那么你错了，结果是[1 2 3]，你可能会觉得很奇怪，slice是引用语义这个在第一个例子中已经证明了，为什么第二个例子中又不是这样呢。 我们对中间过程加一些输出，再来看看 1234567891011func pop(s []int) &#123; fmt.Printf("[pop] s addr:%p\n", &amp;s) s = s[:len(s)-1] fmt.Println("[pop] s value:", s)&#125;func main() &#123; s := []int&#123;1, 2, 3&#125; fmt.Printf("[main] s addr:%p\n", &amp;s) pop(s) fmt.Println("[main] s value:", s)&#125; 运行上面代码输出如下 1234[main] s addr:0xc082004640[pop] s addr:0xc0820046c0[pop] s value: [1 2][main] s value: [1 2 3] 看到上面的结果，可以知道pop()中的s并不是引用，而是一个副本，虽然在pop()内部修改成功，但并没有影响到main()中的s。但第一个例子却修改成功了，这又是为什么。 下面来看下slice的实现，就能很清楚的了解原因了。 slice是由长度固定的数组实现的。当使用内建函数append()向slice添加元素时，如果超过底层的数组长度则会重新分配空间（与C++的vector类似）。 可以把slice认为是下面这样的一个结构体（先不考虑slice的容量）。Lenght表示slice的长度，ZerothElement表示底层数组的头指针 1234type sliceHeader struct &#123; Length int ZerothElement *byte&#125; 参照这个结构体的定义和下面的说明，就能很清楚地了解开始的两个例子了 那当我们需要将slice做为函数参数传入，并且函数会修改slice时，怎么办呢。这里说三种方法。 1.将slice指针做为参数，而不是slice 123func modify(s *[]int) &#123; // do something&#125; 2.把函数内被修改后的slice做为返回值，将函数返回值赋值给原始slice 12345678func modify(s []int) []int &#123; // do something return s&#125;func main() &#123; s := []int&#123;1, 2, 3&#125; s = modify(s)&#125; 3.将函数做为slice指针的方法 12345type slice []intfunc (s *slice) modify() &#123; // do something&#125;]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang在编译时用ldflags设置变量的值]]></title>
    <url>%2F2017%2F01%2Fgolang%E5%9C%A8%E7%BC%96%E8%AF%91%E6%97%B6%E7%94%A8ldflags%E8%AE%BE%E7%BD%AE%E5%8F%98%E9%87%8F%E7%9A%84%E5%80%BC%2F</url>
    <content type="text"><![CDATA[我们经常会在一些程序的输出中看到程序版本、编译时间、Git的commit id等信息，比如docker 123456789ming@vultr:~$ docker versionClient: Version: 1.12.5 API version: 1.24 Go version: go1.6.4 Git commit: 7392c3b Built: Fri Dec 16 02:42:17 2016 OS/Arch: linux/amd64... 我们可以提供一个配置文件version.conf，程序运行时从version.conf取得这些信息进行显示。但是在部署程序时，除了二进制文件还需要额外的配置文件，不是很方便。 或者将这些信息写入代码中，这样不需要额外的version.conf，但要在每次编译时修改代码文件，也够麻烦的了。 有一种更好的办法是在编译时使用参数-ldflags -X importpath.name=value，官方解释如下 -X importpath.name=value Set the value of the string variable in importpath named name to value. Note that before Go 1.5 this option took two separate arguments. Now it takes one argument split on the first = sign. 以下面代码说明 12345678910111213package mainimport "fmt"var ( VERSION string BUILD_TIME string GO_VERSION string)func main() &#123; fmt.Printf("%s\n%s\n%s\n", VERSION, BUILD_TIME, GO_VERSION)&#125; 用如下命令编译，注意因为date和go version的输出有空格，所以main.BUILD_TIME和main.GO_VERSION必须使用引号括起来 1go build -ldflags &quot;-X main.VERSION=1.0.0 -X &apos;main.BUILD_TIME=`date`&apos; -X &apos;main.GO_VERSION=`go version`&apos;&quot; 编译成功后运行程序，结果如下 1234ming@ubuntu:~/go_workspace/src/test$ ./test 1.0.0Sun Feb 12 00:13:27 CST 2017go version go1.7.5 linux/amd64]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[beego orm中时区的问题]]></title>
    <url>%2F2017%2F01%2Fbeego%20orm%E4%B8%AD%E6%97%B6%E5%8C%BA%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[先看简化后代码，下面只列出main函数 12345678910func main() &#123; t := "2017-01-19 00:00:00" o := orm.NewOrm() qb, _ := orm.NewQueryBuilder("mysql") sql := qb.Select("COUNT(*)").From("test").Where("create_time &gt; ?").String() o.Raw(sql, t).Exec() o.QueryTable("test").Filter("create_time__gt", t).Count()&#125; 这么看的话感觉两个SQL应该是相同的： 12[ORM] - 2017-01-19 19:28:02 - [Queries/default] - [ OK / db.Exec / 1.2ms] - [SELECT COUNT(*) FROM test WHERE create_time &gt; ?] - `2017-01-19 00:00:00`[ORM] - 2017-01-19 19:28:02 - [Queries/default] - [ OK / db.QueryRow / 2.3ms] - [SELECT COUNT(*) FROM `test` T0 WHERE T0.`create_time` &gt; ? ] - `2017-01-19 00:00:00` 我在本机测试OK，但在另一个环境SQL是这样的： 12[ORM] - 2017-01-19 11:30:43 - [Queries/default] - [ OK / db.Exec / 1.2ms] - [SELECT COUNT(*) FROM test WHERE create_time &gt; ?] - `2017-01-19 00:00:00`[ORM] - 2017-01-19 11:30:43 - [Queries/default] - [ OK / db.QueryRow / 1.2ms] - [SELECT COUNT(*) FROM `test` T0 WHERE T0.`create_time` &gt; ? ] - `2017-01-19 08:00:00` 相差8小时，第一时间想到时区问题，去有问题的环境一看果真如此。 然后看了下beego orm的代码，下面列出关键部分。 1.orm/db_utils.go的getFlatParams() 此函数是解析Filter()生成SQL的关键部分，如果Filter()第一个参数类型是Date或Datetime，第二个参数类型是string就把string解析成time.Time类型 在上面case中len(v) = 19，执行time.ParseInLocation(formatDateTime, s, DefaultTimeLoc)，因为有问题的环境是UTC时区，所以此函数会把字符串2017-01-19 00:00:00解析成time.Time2017-01-19 00:00:00 +0000 UTC（变量t，但实际是东八区的时间，正确的t应该是2017-01-19 00:00:00 +0800 CST）。 12345678910111213141516171819202122232425262728293031func getFlatParams(fi *fieldInfo, args []interface&#123;&#125;, tz *time.Location) (params []interface&#123;&#125;) &#123;…… switch kind &#123; case reflect.String: v := val.String() if fi != nil &#123; if fi.fieldType == TypeDateField || fi.fieldType == TypeDateTimeField &#123; var t time.Time var err error if len(v) &gt;= 19 &#123; s := v[:19] t, err = time.ParseInLocation(formatDateTime, s, DefaultTimeLoc) &#125; else &#123; s := v if len(v) &gt; 10 &#123; s = v[:10] &#125; t, err = time.ParseInLocation(formatDate, s, tz) &#125; if err == nil &#123; if fi.fieldType == TypeDateField &#123; v = t.In(tz).Format(formatDate) &#125; else &#123; v = t.In(tz).Format(formatDateTime) &#125; &#125; &#125; &#125; arg = v……&#125; 2.t.In(tz).Format(formatDateTime)再次将t格式化为字符串，参数tz是关键，它是在下面代码中赋值的。因为MySQL设置的是东八区，所以会设置al.TZ为东八区，也就是t.In(tz).Format(formatDateTime)中tz是东八区，导致Format返回的字符串是2017-01-19 08:00:00，于是就有了上面两条SQL不同的问题。 12345678910111213141516171819202122func detectTZ(al *alias) &#123; // orm timezone system match database // default use Local al.TZ = time.Local ...... switch al.Driver &#123; case DRMySQL: row := al.DB.QueryRow("SELECT TIMEDIFF(NOW(), UTC_TIMESTAMP)") var tz string row.Scan(&amp;tz) if len(tz) &gt;= 8 &#123; if tz[0] != '-' &#123; tz = "+" + tz &#125; t, err := time.Parse("-07:00:00", tz) if err == nil &#123; al.TZ = t.Location() &#125; else &#123; DebugLog.Printf("Detect DB timezone: %s %s\n", tz, err.Error()) &#125; &#125;......]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ghost修改代码高亮和字体]]></title>
    <url>%2F2017%2F01%2Fghost%E4%BF%AE%E6%94%B9%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE%E5%92%8C%E5%AD%97%E4%BD%93%2F</url>
    <content type="text"><![CDATA[今天开始用ghost，发现默认主题（casper）并没有代码高亮功能，用起来相当不爽。google并看了看ghost主题的代码，找到了解决方法。 在后台找到Code Injection，Blog Header和Blog Footer中分别加入一些代码即可。 修改方法 Blog Header: 12345678910111213&lt;!-- 加载highlight.js样式 --&gt;&lt;link href=&quot;//cdn.bootcss.com/highlight.js/9.9.0/styles/tomorrow-night-eighties.min.css&quot; rel=&quot;stylesheet&quot;&gt;&lt;!-- 加载google字体 --&gt;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;//fonts.googleapis.com/css?family=Droid+Sans+Mono&quot;&gt;&lt;!-- 设置字体 --&gt;&lt;style&gt;body,p,code,h1, h2, h3, h4, h5, h6,.hljs &#123; font-family: &apos;Droid Sans Mono&apos;, monospace;&#125;.hljs &#123; font-size: 0.8em&#125;&lt;/style&gt; Blog Footer: 123&lt;!-- 执行highlight.js --&gt;&lt;script src=&quot;//cdn.bootcss.com/highlight.js/9.9.0/highlight.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt; 原理 查看主题文件themes/casper/default.hbs，可以看到ghost_head和ghost_foot。我们在上面设置Code Injection后就会替换相应内容，从而改变页面显示。 1234567891011&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;!-- 隐藏掉无关信息 --&gt; &#123;&#123;!-- Ghost outputs important style and meta data with this tag --&#125;&#125; &#123;&#123;ghost_head&#125;&#125;&lt;/head&gt;&lt;body class=&quot;&#123;&#123;body_class&#125;&#125; nav-closed&quot;&gt; &#123;&#123;ghost_foot&#125;&#125;&lt;/body&gt;&lt;/html&gt; ghostium主题 ghostium是github上star数较多的一款主题，使用Prism做语法高亮，所以就不再需要自己添加highlight.js了。 如果添加了highlight.js，但markdown格式写错后，就可能会出现这种问题]]></content>
      <tags>
        <tag>ghost</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang闭包]]></title>
    <url>%2F2017%2F01%2Fgolang%E9%97%AD%E5%8C%85%2F</url>
    <content type="text"><![CDATA[有如下函数，简单来说就是有错误则直接返回，没错误则执行f函数。 1234567func (t *transaction) Do(f func()) *transaction &#123; if t.fail || t.rollback || t.finish &#123; return t &#125; f() return t&#125; 函数很简单，但如何测试呢，简单但丑陋的方法： 12345678910111213func Test_func(t *testing.T) &#123; isCalled := false f := func() &#123; isCalled = true &#125; trans := New() // do something trans.Do(f) // check if isCalled &#123; // do something &#125;&#125; 在f中修改外部变量，然后判断变量是否变化就可以知道f是否被执行。但我们一般需要测试多种情况，比如对于Do函数，我们需要将 t.fail t.rollback t.finish设置不同值进行测试，将上面测试代码扩充（如果需要测试这三个变量组合的情况，代码就更长了）： 1234567891011121314151617181920212223242526272829func Test_func(t *testing.T) &#123; isCalled1 := false isCalled2 := false isCalled3 := false f1 := func() &#123; isCalled1 = true &#125; f2 := func() &#123; isCalled2 = true &#125; f3 := func() &#123; isCalled3 = true &#125; trans := New() // do something trans.Do(f1) trans.Do(f2) trans.Do(f3) // check if isCalled1 &#123; // do something &#125; if isCalled2 &#123; // do something &#125; if isCalled3 &#123; // do something &#125;&#125; 在上面代码中f1 f2 f3函数的逻辑都一样，这时可以通过使用闭包来消除冗余代码： 12345678910111213141516171819202122232425262728func Test_func(t *testing.T) &#123; genTestFunc := func() (func(), func() bool) &#123; isCalled := false return func() &#123; isCalled = true &#125;, func() bool &#123; return isCalled &#125; &#125; f1, f1Called := genTestFunc() f2, f2Called := genTestFunc() f3, f3Called := genTestFunc() trans := New() // do something trans.Do(f1) trans.Do(f2) trans.Do(f3) // check if f1Called() &#123; // do something &#125; if f2Called() &#123; // do something &#125; if f3Called() &#123; // do something &#125;&#125; 解释一下，genTestFunc返回值是两个函数，第一个函数可传入Do中，第二个函数用来判断是否被Do调用。 粗略看改动前后代码行数基本相同，但如果f变复杂或者需要更多的测试case时，改动后的代码更加简洁，易于维护。]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解etcd]]></title>
    <url>%2F2017%2F01%2F%E4%BA%86%E8%A7%A3etcd%2F</url>
    <content type="text"><![CDATA[说明 这是一篇非常入门的文章，让你大概了解一下etcd。写这篇文章时使用etcd的版本是3.1.0。 etcd是以实现共享配置和服务发现为目的，提供一致性的键值存储的分布式数据库。kubernetes等项目使用了etcd。 下载安装 去这里下载release包，解压后是一些文档和两个二进制文件etcd和etcdctl。etcd是server端，etcdctl是客户端。将etcd和etcdctl加入PATH路径方便我们执行命令。 运行server 执行命令etcd，即可启动server 1234567891011ming@ming:/tmp$ etcd2017-02-14 14:04:40.164639 I | etcdmain: etcd Version: 3.1.02017-02-14 14:04:40.164725 I | etcdmain: Git SHA: 8ba28972017-02-14 14:04:40.164736 I | etcdmain: Go Version: go1.7.42017-02-14 14:04:40.164776 I | etcdmain: Go OS/Arch: linux/amd642017-02-14 14:04:40.164784 I | etcdmain: setting maximum number of CPUs to 4, total number of available CPUs is 42017-02-14 14:04:40.164850 W | etcdmain: no data-dir provided, using default data-dir ./default.etcd2017-02-14 14:04:40.164934 I | etcdmain: advertising using detected default host &quot;192.168.1.124&quot;2017-02-14 14:04:40.165855 I | embed: listening for peers on http://localhost:23802017-02-14 14:04:40.167090 I | embed: listening for client requests on localhost:2379...... etcdctl 说明：etcd最新的API版本是v3。与v2相比，v3更高效更清晰。设置环境变量ETCDCTL_API=3。 1234ming@ming:/tmp$ export ETCDCTL_API=3ming@ming:/tmp$ etcdctl versionetcdctl version: 3.1.0API version: 3.1 键值对命令 put设置key，get取得key 12345ming@ming:/tmp$ etcdctl put msg &quot;Hello TenxCloud&quot;OKming@ming:/tmp$ etcdctl get msg msgHello TenxCloud del删除key 1234567ming@ming:/tmp$ etcdctl get msg msgHello TenxCloudming@ming:/tmp$ etcdctl del msg1ming@ming:/tmp$ etcdctl get msgming@ming:/tmp$ txn事务 txn从标准输入中读取多个请求，将它们看做一个原子性的事务执行。事务是由条件列表，条件判断成功时的执行列表（条件列表中全部条件为真表示成功）和条件判断失败时的执行列表（条件列表中有一个为假即为失败）组成的。 看文字解释容易晕，来看实例吧 1234567891011121314ming@ming:/tmp$ etcdctl put flag 1OKming@ming:/tmp$ etcdctl txn -icompares:value(&quot;flag&quot;) = &quot;1&quot;success requests (get, put, delete):put result truefailure requests (get, put, delete):put result falseSUCCESSOKming@ming:/tmp$ etcdctl get resultresulttrue 解释一下： etcdctl put flag 1设置flag为1 etcdctl txn -i开启事务（-i表示交互模式） 第2步输入命令后回车，终端显示出compares： 输入value(“flag”) = “1”，此命令是比较flag的值与1是否相等 第4步完成后输入回车，终端会换行显示，此时可以继续输入判断条件（前面说过事务由条件列表组成），再次输入回车表示判断条件输入完毕 第5步连续输入两个回车后，终端显示出success requests (get, put, delete):，表示下面输入判断条件为真时要执行的命令 与输入判断条件相同，连续两个回车表示成功时的执行列表输入完成 终端显示failure requests (get, put, delete):后输入条件判断失败时的执行列表 为了看起来简洁，此实例中条件列表和执行列表只写了一行命令，实际可以输入多行 总结上面的事务，要做的事情就是flag为1时设置result为true，否则设置result为false 事务执行完成后查看result值为true watch监听 watch后etcdctl阻塞，在另一个终端中执行etcdctl put flag 2后，watch会打印出相关信息 1234ming@ming:/tmp$ etcdctl watch flagPUTflag2 lease租约 etcd也能为key设置超时时间，但与redis不同，etcd需要先创建lease，然后使用put命令加上参数–lease=来设置 12345678910111213141516171819202122232425ming@ming:/tmp$ etcdctl lease grant 100lease 38015a3c00490513 granted with TTL(100s)ming@ming:/tmp$ etcdctl put k1 v1 --lease=38015a3c00490513OKming@ming:/tmp$ etcdctl lease timetolive 38015a3c00490513lease 38015a3c00490513 granted with TTL(100s), remaining(67s)ming@ming:/tmp$ etcdctl lease timetolive 38015a3c00490513lease 38015a3c00490513 granted with TTL(100s), remaining(64s)ming@ming:/tmp$ etcdctl lease timetolive 38015a3c00490513 --keyslease 38015a3c00490513 granted with TTL(100s), remaining(59s), attached keys([k1])ming@ming:/tmp$ etcdctl put k2 v2 --lease=38015a3c00490513OKming@ming:/tmp$ etcdctl lease timetolive 38015a3c00490513 --keyslease 38015a3c00490513 granted with TTL(100s), remaining(46s), attached keys([k1 k2])ming@ming:/tmp$ etcdctl lease revoke 38015a3c00490513 lease 38015a3c00490513 revokedming@ming:/tmp$ etcdctl get k1ming@ming:/tmp$ etcdctl get k2ming@ming:/tmp$ ming@ming:/tmp$ etcdctl lease grant 10lease 38015a3c0049051d granted with TTL(10s)ming@ming:/tmp$ etcdctl lease keep-alive 38015a3c0049051dlease 38015a3c0049051d keepalived with TTL(10)lease 38015a3c0049051d keepalived with TTL(10)lease 38015a3c0049051d keepalived with TTL(10) lease grant &lt;ttl&gt; 创建lease，返回lease ID。创建的lease生存时间大于或等于ttl秒（TODO：为什么可能大于？） lease revoke &lt;lease ID&gt; 删除lease，并删除所有关联的key lease timetolive &lt;lease ID&gt; 取得lease的总时间和剩余时间 lease keep-alive &lt;lease ID&gt; 此命令不会只更新一次lease时间，而是周期性地刷新，保证它不会过期。 集群管理命令 TODO 并发控制命令 lock &lt;lock name&gt; 通过指定的名字加锁。注意，只有当正常退出且释放锁后，lock命令的退出码是0，否则这个锁会一直被占用直到过期（默认60秒） 123456789101112131415161718192021222324252627使用Ctrl+C正常退出lock命令，退出码为0，第二次能正常lock：ming@ming:/tmp$ etcdctl lock testtest/38015a3fd6795e04^Cming@ming:/tmp$ echo $?0ming@ming:/tmp$ etcdctl lock testtest/38015a3fd6795e0akill掉lock命令，退出码不为0，第二次lock被阻塞：终端1，第一次正常锁住test：ming@ming:/tmp$ etcdctl lock testtest/38015a3fd6795e11终端2，kill掉lock命令：ming@ming:~$ ps aux|grep &apos;etcdctl lock&apos;ming 44546 0.5 0.5 19876 11436 pts/5 Sl+ 11:42 0:00 etcdctl lock testming 44560 0.0 0.0 14224 1084 pts/6 S+ 11:43 0:00 grep --color=auto etcdctl lockming@ming:~$ kill -9 44546 终端1，退出码不为0，第二次锁test被阻塞ming@ming:/tmp$ etcdctl lock testtest/38015a3fd6795e1eKilledming@ming:/tmp$ echo $?137ming@ming:/tmp$ etcdctl lock test elect TODO 权限 user 可以为etcd创建多个用户并设置密码，子命令有： add 添加用户 delete 删除用户 get 取得用户详情 list 列出所有用户 passwd 修改用户密码 grant-role 给用户分配角色 revoke-role 给用户移除角色 role 可以为etcd创建多个角色并设置权限，子命令有： add 添加角色 delete 删除角色 get 取得角色信息 list 列出所有角色 grant-permission 为角色设置某个key的权限 revoke-permission 为角色移除某个key的权限 auth 开启/关闭权限控制 示例 下面以示例来学习这三个命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263root用户存在时才能开启权限控制ming@ming:/tmp$ etcdctl auth enableError: etcdserver: root user does not existming@ming:/tmp$ etcdctl user add rootPassword of root: Type password of root again for confirmation: User root createdming@ming:/tmp$ etcdctl auth enableAuthentication Enabled 开启权限控制后需要用--user指定用户ming@ming:/tmp$ etcdctl user listError: etcdserver: user name not foundming@ming:/tmp$ etcdctl user list --user=rootPassword: rootming@ming:/tmp$ etcdctl user get root --user=rootPassword: User: rootRoles: root 添加用户，前两个密码是新用户的，后一个密码是root的ming@ming:/tmp$ etcdctl user add mengyuan --user=rootPassword of mengyuan: Type password of mengyuan again for confirmation: Password: User mengyuan created 使用新用户执行put命令，提示没有权限ming@ming:/tmp$ etcdctl put key1 v1 --user=mengyuanPassword: Error: etcdserver: permission denied创建名为rw_key_的role，添加对字符串&quot;key&quot;做为前缀的key的读写权限，为mengyuan添加角色ming@ming:/tmp$ etcdctl role add rw_key_ --user=rootPassword: Role rw_key_ createdming@ming:/tmp$ etcdctl --user=root role grant-permission rw_key_ readwrite key --prefix=truePassword: Role rw_key_ updatedming@ming:/tmp$ etcdctl --user=root user grant-role mengyuan rw_key_Password: Role rw_key_ is granted to user mengyuan 添加权限成功后执行put key1成功，执行put k1失败（因为上面只给前缀为&quot;key&quot;的key添加了权限）ming@ming:/tmp$ etcdctl put key1 v1 --user=mengyuanPassword: OKming@ming:/tmp$ etcdctl put k1 v1 --user=mengyuanPassword: Error: etcdserver: permission denied 执行user list命令失败，没有权限ming@ming:/tmp$ etcdctl user list --user=mengyuanPassword: Error: etcdserver: permission denied为新用户添加root的角色后就能执行user list命令了，注意命令中第一个root是角色，第二个root是用户ming@ming:/tmp$ etcdctl user grant-role mengyuan root --user=rootPassword: Role root is granted to user mengyuanming@ming:/tmp$ etcdctl user list --user=mengyuanPassword: mengyuanroot 进一步学习 etcdctl -h查看子命令的帮助（例：etcdctl watch -h） http://play.etcd.io/play 是网页版集群环境 etcdctl能够设置–prefix=true来操作多个指定前缀的key 参考文档 https://github.com/coreos/etcd https://github.com/coreos/etcd/tree/master/etcdctl]]></content>
      <tags>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解kubernetes的ConfigMap]]></title>
    <url>%2F2017%2F01%2F%E4%BA%86%E8%A7%A3kubernetes%E7%9A%84ConfigMap%2F</url>
    <content type="text"><![CDATA[许多服务在启动/运行时需要读取配置文件、环境变量或命令行参数等信息，我们可以很方便地使用ConfigMap为pod完成这些配置信息的设置与更新。通过下面的例子来了解下ConfigMap吧。 生成ConfigMap 有两个文件info1 info2保存了配置信息 12345678ming@ming-master:~/temp/configmap$ lsinfo1 info2ming@ming-master:~/temp/configmap$ cat info1 name=mengyuancorp=tenxcloudming@ming-master:~/temp/configmap$ cat info2 name=wangleicorp=tenxcloud 执行kubectl create configmap conf --from-file=.命令生成ConfigMap （conf是指定的ConfigMap的名字，--from-file=.指定了当前目录，只会将当前目录下的文件做为配置文件而不去读子目录。也可以从文件或命令行中取得配置，详细参考官网） 12ming@ming-master:~/temp/configmap$ kubectl create configmap conf --from-file=.configmap &quot;conf&quot; created 然后使用kubectl describe configmap查看下刚生成的ConfigMap 12345678910ming@ming-master:~/temp/configmap$ kubectl describe configmap confName: confNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Data====info1: 29 bytesinfo2: 28 bytes 或使用kubectl get configmap *** -o yaml查看详细信息 1234567891011121314151617ming@ming-master:~/temp/configmap$ kubectl get configmap conf -o yamlapiVersion: v1data: info1: | name=mengyuan corp=tenxcloud info2: | name=wanglei corp=tenxcloudkind: ConfigMapmetadata: creationTimestamp: 2016-05-06T19:09:22Z name: conf namespace: default resourceVersion: &quot;4578&quot; selfLink: /api/v1/namespaces/default/configmaps/conf uid: 0aa0a417-13be-11e6-8ead-000c2911326e 在pod中使用ConfigMap ConfigMap生成后如何在pod中使用呢，继续使用上面的例子进行说明。假设我们的容器服务需要info1与info2两个配置文件。 pod文件如下，注意volumeMounts与volumes段，volumeMounts.name要与volumes.name一致，volumes.configMap.name与上面创建的ConfigMap名字一致 1234567891011121314151617ming@ming-master:~/temp/configmap$ cat pod.yaml apiVersion: v1kind: Podmetadata: name: testconfigmapspec: containers: - name: testconfigmap image: index.tenxcloud.com/tenxcloud/ubuntu volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: conf restartPolicy: Never 启动pod 12ming@ming-master:~/temp/configmap$ kubectl create -f pod.yaml pod &quot;testconfigmap&quot; created 启动成功，到slave中的容器看下info1 info2两个文件是否正常 1234567891011ming@ming-slave:~$ docker ps |grep ubuntu.*testconfigmap9431b36fa6f6 index.tenxcloud.com/tenxcloud/ubuntu &quot;/run.sh&quot; About a minute ago Up About a minute k8s_testconfigmap.469034b4_testconfigmap_default_1f88674f-13c5-11e6-8ead-000c2911326e_b0994daaming@ming-slave:~$ docker exec -it k8s_testconfigmap.469034b4_testconfigmap_default_1f88674f-13c5-11e6-8ead-000c2911326e_b0994daa /bin/bashroot@testconfigmap:/# ls /etc/config/info1 info2root@testconfigmap:/# cat /etc/config/info1name=mengyuancorp=tenxcloudroot@testconfigmap:/# cat /etc/config/info2name=wangleicorp=tenxcloud bingo! 更进一步：热更新配置文件 可以使用kubectl replace命令来更新ConfigMap，但此命令格式为kubectl replace -f FILENAME [flags]，-f后面需要指定ConfigMap的配置文件 而上面是用--from-file指定目录取得的配置文件，更新文件后如何更新ConfigMap还没有查到正常的方法，下面说下比较恶心的方法。 1234567891011121314151617ming@ming-master:~/temp$ kubectl get configmap conf -o yamlapiVersion: v1data: info1: | name=mengyuan corp=tenxcloud info2: | name=wanglei corp=tenxcloudkind: ConfigMapmetadata: creationTimestamp: 2016-05-06T19:09:22Z name: conf namespace: default resourceVersion: &quot;5148&quot; selfLink: /api/v1/namespaces/default/configmaps/conf uid: 0aa0a417-13be-11e6-8ead-000c2911326e 取得ConfigMap信息保存到文件再删除/添加内容如下 123456789101112131415ming@ming-master:~/temp$ cat /tmp/configmap apiVersion: v1data: info1: | name=mengyuan corp=tenxcloud add new line 1 info2: | name=wanglei corp=tenxcloud add new line 2kind: ConfigMapmetadata: name: conf namespace: default 然后再使用kubectl replace修改ConfigMap 12ming@ming-master:~/temp$ kubectl replace -f /tmp/configmap configmap &quot;conf&quot; replaced 成功，切回slave看下配置文件 12345678root@testconfigmap:/# cat /etc/config/info1name=mengyuancorp=tenxcloudadd new line 1root@testconfigmap:/# cat /etc/config/info2name=wangleicorp=tenxcloudadd new line 2 修改成功 一些限制及问题 当create ConfigMap时–from-file指定的是目录时，在更新文件后，如何正常的更新ConfigMap 如何为有子目录的配置目录生成ConfigMap（子目录中也有配置文件） 配置文件不能实时更新，在master上使用kubectrl replace或kubectl edit更新configmap后，相关pod内的文件延迟更新（测试两次30s，1min）（下一次syncLoop时，才会更新配置） 环境变量更新后旧Pod内环境变量不会改变，新启动的Pod是最新的环境变量 配置文件名（做为configmap.data中的key名字）有限制，Data contains the configuration data. Each key must be a valid DNS_SUBDOMAIN with an optional leading dot（可以有横线-点.小写字母） 参考资料 官网 HowTo Write ConfigMap enabled Golang Microservices ConfigMap的设计]]></content>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go的内存模型]]></title>
    <url>%2F2017%2F01%2FGo%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[说明 翻译自The Go Memory Model 介绍 如何保证在一个goroutine中看到在另一个goroutine修改的变量的值，这篇文章进行了详细说明。 建议 如果程序中修改数据时有其他goroutine同时读取，那么必须将读取串行化。为了串行化访问，请使用channel或其他同步原语，例如sync和sync/atomic来保护数据。 先行发生 在一个gouroutine中，读和写一定是按照程序中的顺序执行的。即编译器和处理器只有在不会改变这个goroutine的行为时才可能修改读和写的执行顺序。由于重排，不同的goroutine可能会看到不同的执行顺序。例如，一个goroutine执行a = 1;b = 2;，另一个goroutine可能看到b在a之前更新。 为了说明读和写的必要条件，我们定义了先行发生（Happens Before）–Go程序中执行内存操作的偏序。如果事件e1发生在e2前，我们可以说e2发生在e1后。如果e1不发生在e2前也不发生在e2后，我们就说e1和e2是并发的。 在单独的goroutine中先行发生的顺序即是程序中表达的顺序。 当下面条件满足时，对变量 v 的读操作 r 是 被允许 看到对 v 的写操作 w 的： r 不先行发生于 w 在 w 后 r 前没有对 v 的其他写操作 为了保证对变量 v 的读操作 r 看到对 v 的写操作 w ,要确保 w 是 r 允许看到的唯一写操作。即当下面条件满足时， r 被保证 看到 w ： w 先行发生于 r 其他对共享变量 v 的写操作要么在 w 前，要么在 r 后。 这一对条件比前面的条件更严格，需要没有其他写操作与 w 或 r 并发发生。 单独的goroutine中没有并发，所以上面两个定义是相同的：读操作 r 看到最近一次的写操作 w 写入 v 的值。当多个goroutine访问共享变量 v 时，它们必须使用同步事件来建立先行发生这一条件来保证读操作能看到需要的写操作。 对变量 v 的零值初始化在内存模型中表现的与写操作相同。 对大于一个字的变量的读写操作表现的像以不确定顺序对多个一字大小的变量的操作。 同步 初始化 程序的初始化在单独的goroutine中进行，但这个goroutine可能会创建出并发执行的其他goroutine。 如果包p引入（import）包q，那么q的init函数的结束先行发生于p的所有init函数开始 main.main函数的开始发生在所有init函数结束之后 创建goroutine go关键字开启新的goroutine，先行发生于这个goroutine开始执行，例如下面程序： 12345678910var a stringfunc f() &#123; print(a)&#125;func hello() &#123; a = "hello, world" go f()&#125; 调用hello会在之后的某时刻打印出&quot;hello, world&quot;（可能在hello返回之后） 销毁goroutine gouroutine的退出并不会保证先行发生于程序的任何事件。例如下面程序： 123456var a stringfunc hello() &#123; go func() &#123; a = "hello" &#125;() print(a)&#125; 没有用任何同步操作限制对a的赋值，所以并不能保证其他goroutine能看到a的变化。实际上，一个激进的编译器可能会删掉整个go语句。 如果想要在一个goroutine中看到另一个goroutine的执行效果，请使用锁或者channel这种同步机制来建立程序执行的相对顺序。 channel通信 channel通信是goroutine同步的主要方法。每一个在特定channel的发送操作都会匹配到通常在另一个goroutine执行的接收操作。 在channel的发送操作先行发生于对应的接收操作完成 例如： 12345678910111213var c = make(chan int, 10)var a stringfunc f() &#123; a = "hello, world" c &lt;- 0&#125;func main() &#123; go f() &lt;-c print(a)&#125; 这个程序能保证打印出&quot;hello, world&quot;。对a的写先行发生于在c上的发送，先行发生于在c上的对应的接收完成，先行发生于print。 对channel的关闭先行发生于接收到零值，因为channel已经被关闭了。 在上面的例子中，将c &lt;- 0替换为close(c)还会产生同样的结果。 无缓冲channel的接收先行发生于发送完成 如下程序（和上面类似，只交换了对channel的读写位置并使用了非缓冲channel）： 1234567var c = make(chan int)var a stringfunc f() &#123; a = "hello, world" &lt;-c&#125; 12345func main() &#123; go f() c &lt;- 0 print(a)&#125; 此程序也能保证打印出&quot;hello, world&quot;。对a的写先行发生于从c接收，先行发生于向c发送完成，先行发生于print。 如果是带缓冲的channel（例如c = make(chan int, 1)），程序不保证打印出&quot;hello, world&quot;(可能打印空字符，程序崩溃或其他行为)。 在容量为C的channel上的第k个接收先行发生于从这个channel上的第k+C次发送完成。 这条规则将前面的规则推广到了带缓冲的channel上。可以通过带缓冲的channel来实现计数信号量：channel中的元素数量对应着活动的数量，channel的容量表示同时活动的最大数量，发送元素获取信号量，接收元素释放信号量，这是限制并发的通常用法。 下面程序为work中的每一项开启一个goroutine，但这些goroutine通过有限制的channel来确保最多同时执行三个工作函数（w）。 123456789101112var limit = make(chan int, 3)func main() &#123; for _, w := range work &#123; go func(w func()) &#123; limit &lt;- 1 w() &lt;-limit &#125;(w) &#125; select&#123;&#125;&#125; 锁 sync包实现了两个锁的数据类型sync.Mutex和sync.RWMutex。 对任意的sync.Mutex或sync.RWMutex变量l和n &lt; m，n次调用l.Unlock()先行发生于m次l.Lock()返回 下面程序： 1234567891011121314var l sync.Mutexvar a stringfunc f() &#123; a = "hello, world" l.Unlock()&#125;func main() &#123; l.Lock() go f() l.Lock() print(a)&#125; 能保证打印出&quot;hello, world&quot;。第一次调用l.Unlock()（在f()中）先行发生于main中的第二次l.Lock()返回, 先行发生于print。 对于sync.RWMutex变量l，任意的函数调用l.RLock满足第n次l.RLock后发生于第n次调用l.Unlock，对应的l.RUnlock先行发生于第n+1次调用l.Lock。 Once sync包的Once为多个goroutine提供了安全的初始化机制。能在多个线程中执行once.Do(f)，但只有一个f()会执行，其他调用会一直阻塞直到f()返回。 通过once.Do(f)执行f()先行发生（指f()返回）于其他的once.Do(f)返回。 如下程序： 12345678910111213141516var a stringvar once sync.Oncefunc setup() &#123; a = "hello, world"&#125;func doprint() &#123; once.Do(setup) print(a)&#125;func twoprint() &#123; go doprint() go doprint()&#125; 调用twoprint会打印&quot;hello, world&quot;两次。setup只在第一次doprint时执行。 错误的同步方法 注意，读操作 r 可能会看到并发的写操作 w 。即使这样也不能表明 r 之后的读能看到 w 之前的写。 如下程序： 12345678910111213141516var a, b intfunc f() &#123; a = 1 b = 2&#125;func g() &#123; print(b) print(a)&#125;func main() &#123; go f() g()&#125; g可能先打印出2然后是0。 这个事实证明一些旧的习惯是错误的。 双重检查锁定是为了避免同步的资源消耗。例如twoprint程序可能会错误的写成： 12345678910111213141516171819var a stringvar done boolfunc setup() &#123; a = "hello, world" done = true&#125;func doprint() &#123; if !done &#123; once.Do(setup) &#125; print(a)&#125;func twoprint() &#123; go doprint() go doprint()&#125; 在doprint中看到done被赋值并不保证能看到对a赋值。此程序可能会错误地输出空字符而不是&quot;hello, world&quot;。 另一个错误的习惯是忙等待 例如： 1234567891011121314var a stringvar done boolfunc setup() &#123; a = "hello, world" done = true&#125;func main() &#123; go setup() for !done &#123; &#125; print(a)&#125; 和之前程序类似，在main中看到done被赋值不能保证看到a被赋值，所以此程序也可能打印出空字符。更糟糕的是因为两个线程间没有同步事件，在main中可能永远不会看到done被赋值，所以main中的循环不保证能结束。 对程序做一个微小的改变： 123456789101112131415161718type T struct &#123; msg string&#125;var g *Tfunc setup() &#123; t := new(T) t.msg = "hello, world" g = t&#125;func main() &#123; go setup() for g == nil &#123; &#125; print(g.msg)&#125; 即使main看到了g != nil并且退出了循环，也不能保证看到g.msg的初始化值。 在上面所有的例子中，解决办法都是相同的：明确的使用同步。]]></content>
  </entry>
  <entry>
    <title><![CDATA[常用命令]]></title>
    <url>%2F2017%2F01%2F%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[shell 1234567891011121314scp复制多个文件，并且不需要输入yesscp -o &quot;StrictHostKeyChecking no&quot; 20150603.tar.gz 20150627.tar.gz 20150705.tar.gz user@host:/home/users/log/20150715/`hostname`for i in `seq -f %02g 0 23`;do file=&quot;log/pay.log.20150731&quot;$i; echo $file;done查看svn密码~/.subversion/auth/svn.simple/48eed6299865c0af1dac26d1a6d79efamutt发邮件mutt -e &quot;my_hdr content-type:text/html&quot; -s &quot;subject&quot; &quot;user@baidu.com&quot; &lt; mail.html列出文件中排名前10的行及数量 sort file | uniq -c | sort -k 1 -n -r | head -10格式化json输出`cat /tmp/json |python -m json.tool`输出文件指定行cat filename| head -n 3000 | tail -n +1000（显示1000行到3000行），cat filename | tail -n +3000 | head -n 1000（从第3000行开始，显示1000行。即显示3000~3999行） sed 1sed -i &quot;s/old/new/g&quot; `grep -rl &apos;../../static/&apos; *` sed批量替换多个文件的内容 golang 123456编译时支持GDB调试：1传递参数-ldflags &quot;-s&quot;，忽略debug的打印信息2传递-gcflags &quot;-N -l&quot; 参数，这样可以忽略Go内部做的一些优化，聚合变量和函数等优化，这样对于GDB调试来说非常困难，所以在编译的时候加入这两个参数避免这些优化3编译为静态程序CGO_ENABLED=&quot;0&quot; go build hello.gokill -3 &lt;pid&gt;发送SIGQUIT信号，会将正在运行的goroutine的调用栈输出 gdb 123456789gdb在文件上加断点时避免每次使用很长的完整路径，可使用dir(gdb) dir /home/yourihua/workplace/rhino/src/github.com/robfig/revel/Source directories searched: /home/yourihua/workplace/rhino/src/github.com/robfig/revel:$cdir:$cwd(gdb) b revel.go:86Breakpoint 2 at 0x44ef60: file /home/yourihua/workplace/rhino/src/github.com/robfig/revel/revel.go, line 86.打印vector前N个元素print *(myVector._M_impl._M_start)@N设置调试程序的参数(gdb) set args arg1 arg2 ... git 1234567891011121314151617181920212223242526272829git diff 查看尚未暂存的文件更新了哪些部分 git diff filename 查看尚未暂存的某个文件更新了哪些 git diff –cached 查看已经暂存起来的文件和上次提交的版本之间的差异 git diff –cached filename 查看已经暂存起来的某个文件和上次提交的版本之间的差异 git diff ffd98b291e0caa6c33575c1ef465eae661ce40c9 b8e7b00c02b95b320f14b625663fdecf2d63e74c 查看某两个版本之间的差异 git diff ffd98b291e0caa6c33575c1ef465eae661ce40c9:filename b8e7b00c02b95b320f14b625663fdecf2d63e74c:filename 查看某两个版本的某个文件之间的差异git log &lt;commit-id&gt; --stat 查看指定commit修改的哪些文件git checkout -t origin/2.0.0 将本地分支切换为远程分支git config --global core.excludesfile ~/.gitignore 全局忽略git log --pretty=format:&quot;%h - %an, %ar : %s&quot; 输出commtid - author - commit time - commit msggit show &lt;commitid&gt; &lt;file&gt; 查看某次commit对文件的修改git update-index --assume-unchanged your_file_path 不想继续追踪某个文件git update-index --no-assume-unchanged your_file_path 如果想再次继续跟踪某个文件git co -b release-2.0.1 upstream/release-2.0.1 将远程分支checkout到本地git cherry-pick &lt;commit-id&gt; 将某个commit应用到当前分支 vim 12345678910111213141516:w !sudo tee % 保存时取得sudo权限加入行号 :&apos;&lt;,&apos;&gt;s/BIT_MASK_\zs\d*\ze/\=line(&quot;.&quot;) - line(&quot;&apos;&lt;&quot;) + 1，解释：&apos;&lt;,&apos;&gt; 我们所选中的区域 (:help &apos;&lt;，:help &apos;&gt; )s 在选中的区域中进行替换 (:help :s )\zs 指明匹配由此开始 (:help /\zs )\d* 查找任意位数的数字 (:help /\d )\ze 指明匹配到此为止 (:help /\ze )\= 指明后面是一个表达式 (:help :s\= )line(&quot;.&quot;) 当前光标所在行的行号 (:help line() )line(&quot;&apos;&lt;&quot;) 我们所选区域中第一行的行号 (:help line() ) 当”:s”命令的替换字符串是以”\=”开头时，表明使用一个表达式计算的结果进行替换去除重复的行1.先排序:sort2.然后不要同时排序:sor ur /^/ fiddler 1bpafter &lt;part_url&gt;：URL中含有part_url时中断，可修改响应然后返回给浏览器 redis 1cat &lt;file_name&gt; | redis-cli --pipe 一次执行多条redis命令（比如导入大量数据） vs code 12settings.json&quot;editor.renderWhitespace&quot;:true // 显示空白字符m]]></content>
  </entry>
</search>
